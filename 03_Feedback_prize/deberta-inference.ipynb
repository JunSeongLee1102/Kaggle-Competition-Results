{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ì¶œì²˜: https://www.kaggle.com/code/batprem/deberta-layerwiselr-lastlayerreini-infer","metadata":{}},{"cell_type":"markdown","source":"# ðŸ¤—DeBERTa LLRD + LastLayerReinit with TensorFlow\n\nHi, everyone! This notebook is a DeBERTaV3 finetuning solution to [Feedback Prize - English Language Learning competition](https://www.kaggle.com/competitions/feedback-prize-english-language-learning). It features:\n\n* MultilabelStratifiedKFold split of the data\n* HuggingFace DeBERTaV3 pre-trained model finetuning with Tensorflow\n* WeightedLayerPool + MeanPool TensorFlow implementation\n* Layer-wise learning rate decay\n* Last layer reinitialization or partially reinitialzation\n\n\nIn this compitition, I also have the following notebooks:\n\n* LB 0.44 - [DeBERTa WeightedLayerPool + MeanPool](https://www.kaggle.com/code/electro/debertav3-weightedlayermeanpool-kfold-tensorflow)\n* LB 0.44 - [RoBERTa MeanPool](https://www.kaggle.com/code/electro/fp3-roberta-meanpool-kfold-tensorflow)\n* LB 0.46 - [BERT CLS finetuning](https://www.kaggle.com/code/electro/fp3-bert-fine-tuning-tensorflow) | [BERT CLS inference](https://www.kaggle.com/code/electro/fp3-bert-inference-tensorflow)\n* LB 0.53 - [basic EDA and bag-of-words solution](https://www.kaggle.com/code/electro/fp3-bag-of-words-tensorflow-starter). \n\nPlease check them out if you are interested. \n\nIf you like this notebook, please upvote it. Thank you.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os, gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nprint(f'TF version: {tf.__version__}')\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import layers\n\nimport transformers\nprint(f'transformers version: {transformers.__version__}')\nfrom transformers import logging as hf_logging\nhf_logging.set_verbosity_error()\n\nimport sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:51.679758Z","iopub.execute_input":"2022-11-29T19:06:51.680219Z","iopub.status.idle":"2022-11-29T19:06:58.087375Z","shell.execute_reply.started":"2022-11-29T19:06:51.680140Z","shell.execute_reply":"2022-11-29T19:06:58.086358Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"TF version: 2.6.4\ntransformers version: 4.20.1\n","output_type":"stream"}]},{"cell_type":"code","source":"def set_seed(seed=42):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:58.089407Z","iopub.execute_input":"2022-11-29T19:06:58.089998Z","iopub.status.idle":"2022-11-29T19:06:58.101676Z","shell.execute_reply.started":"2022-11-29T19:06:58.089969Z","shell.execute_reply":"2022-11-29T19:06:58.099443Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load DataFrame","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/feedback-prize-english-language-learning/train.csv')\ndisplay(df.head())\nprint('\\n---------DataFrame Summary---------')\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:58.103214Z","iopub.execute_input":"2022-11-29T19:06:58.103883Z","iopub.status.idle":"2022-11-29T19:06:58.373370Z","shell.execute_reply.started":"2022-11-29T19:06:58.103844Z","shell.execute_reply":"2022-11-29T19:06:58.372400Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"        text_id                                          full_text  cohesion  \\\n0  0016926B079C  I think that students would benefit from learn...       3.5   \n1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n3  003885A45F42  The best time in life is when you become yours...       4.5   \n4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n\n   syntax  vocabulary  phraseology  grammar  conventions  \n0     3.5         3.0          3.0      4.0          3.0  \n1     2.5         3.0          2.0      2.0          2.5  \n2     3.5         3.0          3.0      3.0          2.5  \n3     4.5         4.5          4.5      4.0          5.0  \n4     3.0         3.0          3.0      2.5          2.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n---------DataFrame Summary---------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3911 entries, 0 to 3910\nData columns (total 8 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   text_id      3911 non-null   object \n 1   full_text    3911 non-null   object \n 2   cohesion     3911 non-null   float64\n 3   syntax       3911 non-null   float64\n 4   vocabulary   3911 non-null   float64\n 5   phraseology  3911 non-null   float64\n 6   grammar      3911 non-null   float64\n 7   conventions  3911 non-null   float64\ndtypes: float64(6), object(2)\nmemory usage: 244.6+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# CV Split","metadata":{}},{"cell_type":"code","source":"N_FOLD = 5\nTARGET_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n\nskf = MultilabelStratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=42)\nfor n, (train_index, val_index) in enumerate(skf.split(df, df[TARGET_COLS])):\n    df.loc[val_index, 'fold'] = int(n)\ndf['fold'] = df['fold'].astype(int)\ndf['fold'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:58.376569Z","iopub.execute_input":"2022-11-29T19:06:58.376857Z","iopub.status.idle":"2022-11-29T19:06:58.507149Z","shell.execute_reply.started":"2022-11-29T19:06:58.376832Z","shell.execute_reply":"2022-11-29T19:06:58.506071Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1    783\n0    782\n4    782\n3    782\n2    782\nName: fold, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv('./df_folds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:58.508860Z","iopub.execute_input":"2022-11-29T19:06:58.509276Z","iopub.status.idle":"2022-11-29T19:06:58.650412Z","shell.execute_reply.started":"2022-11-29T19:06:58.509235Z","shell.execute_reply":"2022-11-29T19:06:58.649445Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model Config","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH = 512\nBATCH_SIZE = 4\nDEBERTA_MODEL = \"../input/debertav3base\"","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:58.651989Z","iopub.execute_input":"2022-11-29T19:06:58.652366Z","iopub.status.idle":"2022-11-29T19:06:58.657176Z","shell.execute_reply.started":"2022-11-29T19:06:58.652327Z","shell.execute_reply":"2022-11-29T19:06:58.656042Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Why we should disable dropout in regression task, check this [discussion](https://www.kaggle.com/competitions/commonlitreadabilityprize/discussion/260729).","metadata":{}},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(DEBERTA_MODEL)\ntokenizer.save_pretrained('./tokenizer/')\n\ncfg = transformers.AutoConfig.from_pretrained(DEBERTA_MODEL, output_hidden_states=True)\ncfg.hidden_dropout_prob = 0\ncfg.attention_probs_dropout_prob = 0\ncfg.save_pretrained('./tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:06:58.658698Z","iopub.execute_input":"2022-11-29T19:06:58.659078Z","iopub.status.idle":"2022-11-29T19:07:00.626576Z","shell.execute_reply.started":"2022-11-29T19:06:58.659042Z","shell.execute_reply":"2022-11-29T19:07:00.624368Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Process Function\n\nTo make use of HugggingFace DeBERTa model, we have to tokenize our input texts as the pretrained DeBERTa model requires.","metadata":{}},{"cell_type":"code","source":"def deberta_encode(texts, tokenizer=tokenizer):\n    input_ids = []\n    attention_mask = []\n    \n    for text in texts.tolist():\n        token = tokenizer(text, \n                          add_special_tokens=True, \n                          max_length=MAX_LENGTH, \n                          return_attention_mask=True, \n                          return_tensors=\"np\", \n                          truncation=True, \n                          padding='max_length')\n        input_ids.append(token['input_ids'][0])\n        attention_mask.append(token['attention_mask'][0])\n    \n    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:00.631151Z","iopub.execute_input":"2022-11-29T19:07:00.631716Z","iopub.status.idle":"2022-11-29T19:07:00.642667Z","shell.execute_reply.started":"2022-11-29T19:07:00.631675Z","shell.execute_reply":"2022-11-29T19:07:00.641707Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_dataset(df):\n    inputs = deberta_encode(df['full_text'])\n    targets = np.array(df[TARGET_COLS], dtype=\"float32\")\n    return inputs, targets","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:00.646675Z","iopub.execute_input":"2022-11-29T19:07:00.647415Z","iopub.status.idle":"2022-11-29T19:07:00.657943Z","shell.execute_reply.started":"2022-11-29T19:07:00.647377Z","shell.execute_reply":"2022-11-29T19:07:00.656904Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model\n\n## MeanPool\n\nInstead of using '[CLS]' token, MeanPool method averaging one layer of hidden states along the sequence axis with masking out padding tokens.\n\n## WeightedLayerPool\n\nWeightedLayerPool uses a set of trainable weights to average a set of hidden states from transformer backbone. I use a Dense layer with constraint to implement it.","metadata":{}},{"cell_type":"code","source":"class MeanPool(tf.keras.layers.Layer):\n    def call(self, inputs, mask=None):\n        broadcast_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n        embedding_sum = tf.reduce_sum(inputs * broadcast_mask, axis=1)\n        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n        return embedding_sum / mask_sum","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:00.665673Z","iopub.execute_input":"2022-11-29T19:07:00.667924Z","iopub.status.idle":"2022-11-29T19:07:00.676151Z","shell.execute_reply.started":"2022-11-29T19:07:00.667884Z","shell.execute_reply":"2022-11-29T19:07:00.675175Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"WeightedLayerPool weights constraints: softmax to push sum(w) to be 1.","metadata":{}},{"cell_type":"code","source":"class WeightsSumOne(tf.keras.constraints.Constraint):\n    def __call__(self, w):\n        return tf.nn.softmax(w, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:00.680919Z","iopub.execute_input":"2022-11-29T19:07:00.683300Z","iopub.status.idle":"2022-11-29T19:07:00.690134Z","shell.execute_reply.started":"2022-11-29T19:07:00.683264Z","shell.execute_reply":"2022-11-29T19:07:00.689094Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model Design Choice\n\nAlthough there are many ways to get your final representations, I choose to take the last 4 layers hidden states of DeBERTa, take MeanPool of them to gather information along the sequence axis, then take WeightedLayerPool with a set of trainable weights to gather information along the depth axis of the model, then finally a regression head.\n\n## Last Layer Reinitialization\n\nReinitialization of the last transformer encoder block: GlorotUniform for Dense kernel, Zeros for Dense bias, Zeros for LayerNorm beta, Ones for LayerNorm gamma.\n\n## Layer-wise Learning Rate Decay\n\nI use MultiOptimizer to implement LLRD: Initial learning rate 1e-5 with layer-wise decay 0.9 for transformer encoder and embedding block, 1e-4 for the rest of the model. All learning rates have ExponentialDecay schedulers with decay rate 0.3","metadata":{}},{"cell_type":"code","source":"def get_model():\n    input_ids = tf.keras.layers.Input(\n        shape=(MAX_LENGTH,), dtype=tf.int32, name=\"input_ids\"\n    )\n    \n    attention_masks = tf.keras.layers.Input(\n        shape=(MAX_LENGTH,), dtype=tf.int32, name=\"attention_masks\"\n    )\n   \n    deberta_model = transformers.TFAutoModel.from_pretrained(DEBERTA_MODEL, config=cfg)\n    \n    #Last Layer Reinitialization or Partially Reinitialization\n#     Uncommon next three lines to check deberta encoder block\n#     print('DeBERTa Encoder Block:')\n#     for layer in deberta_model.deberta.encoder.layer:\n#         print(layer)\n        \n    REINIT_LAYERS = 1\n    normal_initializer = tf.keras.initializers.GlorotUniform()\n    zeros_initializer = tf.keras.initializers.Zeros()\n    ones_initializer = tf.keras.initializers.Ones()\n\n#     print(f'\\nRe-initializing encoder block:')\n    for encoder_block in deberta_model.deberta.encoder.layer[-REINIT_LAYERS:]:\n#         print(f'{encoder_block}')\n        for layer in encoder_block.submodules:\n            if isinstance(layer, tf.keras.layers.Dense):\n                layer.kernel.assign(normal_initializer(shape=layer.kernel.shape, dtype=layer.kernel.dtype))\n                if layer.bias is not None:\n                    layer.bias.assign(zeros_initializer(shape=layer.bias.shape, dtype=layer.bias.dtype))\n\n            elif isinstance(layer, tf.keras.layers.LayerNormalization):\n                layer.beta.assign(zeros_initializer(shape=layer.beta.shape, dtype=layer.beta.dtype))\n                layer.gamma.assign(ones_initializer(shape=layer.gamma.shape, dtype=layer.gamma.dtype))\n\n    deberta_output = deberta_model.deberta(\n        input_ids, attention_mask=attention_masks\n    )\n    hidden_states = deberta_output.hidden_states\n    \n    #WeightedLayerPool + MeanPool of the last 4 hidden states\n    stack_meanpool = tf.stack(\n        [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidden_states[-4:]], \n        axis=2)\n    \n    weighted_layer_pool = layers.Dense(1,\n                                       use_bias=False,\n                                       kernel_constraint=WeightsSumOne())(stack_meanpool)\n    \n    weighted_layer_pool = tf.squeeze(weighted_layer_pool, axis=-1)\n    \n    x = layers.Dense(6, activation='sigmoid')(weighted_layer_pool)\n    output = layers.Rescaling(scale=4.0, offset=1.0)(x)\n    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n    \n    #Compile model with Layer-wise Learning Rate Decay\n    layer_list = [deberta_model.deberta.embeddings] + list(deberta_model.deberta.encoder.layer)\n    layer_list.reverse()\n    \n    INIT_LR = 1e-5\n    LLRDR = 0.9\n    LR_SCH_DECAY_STEPS = 1600 # 2 * len(train_df) // BATCH_SIZE\n    \n    lr_schedules = [tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=INIT_LR * LLRDR ** i, \n        decay_steps=LR_SCH_DECAY_STEPS, \n        decay_rate=0.3) for i in range(len(layer_list))]\n    lr_schedule_head = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=1e-4, \n        decay_steps=LR_SCH_DECAY_STEPS, \n        decay_rate=0.3)\n    \n    optimizers = [tf.keras.optimizers.Adam(learning_rate=lr_sch) for lr_sch in lr_schedules]\n    \n    optimizers_and_layers = [(tf.keras.optimizers.Adam(learning_rate=lr_schedule_head), model.layers[-4:])] +\\\n        list(zip(optimizers, layer_list))\n    \n#     Uncomment next three lines to check optimizers_and_layers\n#     print('\\nLayer-wise Learning Rate Decay Initial LR:')\n#     for o,l in optimizers_and_layers:\n#         print(f'{o._decayed_lr(\"float32\").numpy()} for {l}')\n        \n    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n    \n    model.compile(optimizer=optimizer,\n                 loss='huber_loss',\n                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                 )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:00.695066Z","iopub.execute_input":"2022-11-29T19:07:00.697293Z","iopub.status.idle":"2022-11-29T19:07:00.720694Z","shell.execute_reply.started":"2022-11-29T19:07:00.697256Z","shell.execute_reply":"2022-11-29T19:07:00.719535Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:00.725565Z","iopub.execute_input":"2022-11-29T19:07:00.728224Z","iopub.status.idle":"2022-11-29T19:07:27.472392Z","shell.execute_reply.started":"2022-11-29T19:07:00.728186Z","shell.execute_reply":"2022-11-29T19:07:27.471395Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2022-11-29 19:07:02.447522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:02.449064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:02.450075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:02.451364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-29 19:07:02.451708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:02.452782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:02.453807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:07.393231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:07.394385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:07.395347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-29 19:07:07.396167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15043 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-11-29 19:07:18.046459: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\nattention_masks (InputLayer)    [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ndeberta (TFDebertaV2MainLayer)  TFBaseModelOutput(la 183831552   input_ids[0][0]                  \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\nmean_pool (MeanPool)            (None, 768)          0           deberta[0][9]                    \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\nmean_pool_1 (MeanPool)          (None, 768)          0           deberta[0][10]                   \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\nmean_pool_2 (MeanPool)          (None, 768)          0           deberta[0][11]                   \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\nmean_pool_3 (MeanPool)          (None, 768)          0           deberta[0][12]                   \n                                                                 attention_masks[0][0]            \n__________________________________________________________________________________________________\ntf.stack (TFOpLambda)           (None, 768, 4)       0           mean_pool[0][0]                  \n                                                                 mean_pool_1[0][0]                \n                                                                 mean_pool_2[0][0]                \n                                                                 mean_pool_3[0][0]                \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 768, 1)       4           tf.stack[0][0]                   \n__________________________________________________________________________________________________\ntf.compat.v1.squeeze (TFOpLambd (None, 768)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 6)            4614        tf.compat.v1.squeeze[0][0]       \n__________________________________________________________________________________________________\nrescaling (Rescaling)           (None, 6)            0           dense_1[0][0]                    \n==================================================================================================\nTotal params: 183,836,170\nTrainable params: 183,836,170\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5 Folds Training Loop","metadata":{}},{"cell_type":"code","source":"'''\nvalid_rmses = []\nfor fold in range(N_FOLD):\n    print(f'\\n-----------FOLD {fold} ------------')\n    \n    #Create dataset\n    train_df = df[df['fold'] != fold].reset_index(drop=True)\n    valid_df = df[df['fold'] == fold].reset_index(drop=True)\n    train_dataset = get_dataset(train_df)\n    valid_dataset = get_dataset(valid_df)\n    \n    print('Data prepared.')\n    print(f'Training data input_ids shape: {train_dataset[0][0].shape} dtype: {train_dataset[0][0].dtype}') \n    print(f'Training data attention_mask shape: {train_dataset[0][1].shape} dtype: {train_dataset[0][1].dtype}')\n    print(f'Training data targets shape: {train_dataset[1].shape} dtype: {train_dataset[1].dtype}')\n    print(f'Validation data input_ids shape: {valid_dataset[0][0].shape} dtype: {valid_dataset[0][0].dtype}')\n    print(f'Validation data attention_mask shape: {valid_dataset[0][1].shape} dtype: {valid_dataset[0][1].dtype}')\n    print(f'Validation data targets shape: {valid_dataset[1].shape} dtype: {valid_dataset[1].dtype}')\n    \n    #Create model\n    tf.keras.backend.clear_session()\n    model = get_model()\n    print('Model prepared.')\n    \n    #Training model\n    print('Start training...')\n    callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(f\"best_model_fold{fold}.h5\",\n                                       monitor=\"val_loss\",\n                                       mode=\"min\",\n                                       save_best_only=True,\n                                       verbose=1,\n                                       save_weights_only=True,),\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                     min_delta=1e-5, \n                                     patience=3, \n                                     verbose=1,\n                                     mode='min',)\n    ]\n    history = model.fit(x=train_dataset[0],\n                        y=train_dataset[1],\n                        validation_data=valid_dataset, \n                        epochs=10,\n                        shuffle=True,\n                        batch_size=BATCH_SIZE,\n                        callbacks=callbacks\n                       )\n    \n    valid_rmses.append(np.min(history.history['val_root_mean_squared_error']))\n    print('Training finished.')\n    del train_dataset, valid_dataset, train_df, valid_df\n    gc.collect()\n'''    ","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:27.473943Z","iopub.execute_input":"2022-11-29T19:07:27.474757Z","iopub.status.idle":"2022-11-29T19:07:27.483562Z","shell.execute_reply.started":"2022-11-29T19:07:27.474716Z","shell.execute_reply":"2022-11-29T19:07:27.482464Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'\\nvalid_rmses = []\\nfor fold in range(N_FOLD):\\n    print(f\\'\\n-----------FOLD {fold} ------------\\')\\n    \\n    #Create dataset\\n    train_df = df[df[\\'fold\\'] != fold].reset_index(drop=True)\\n    valid_df = df[df[\\'fold\\'] == fold].reset_index(drop=True)\\n    train_dataset = get_dataset(train_df)\\n    valid_dataset = get_dataset(valid_df)\\n    \\n    print(\\'Data prepared.\\')\\n    print(f\\'Training data input_ids shape: {train_dataset[0][0].shape} dtype: {train_dataset[0][0].dtype}\\') \\n    print(f\\'Training data attention_mask shape: {train_dataset[0][1].shape} dtype: {train_dataset[0][1].dtype}\\')\\n    print(f\\'Training data targets shape: {train_dataset[1].shape} dtype: {train_dataset[1].dtype}\\')\\n    print(f\\'Validation data input_ids shape: {valid_dataset[0][0].shape} dtype: {valid_dataset[0][0].dtype}\\')\\n    print(f\\'Validation data attention_mask shape: {valid_dataset[0][1].shape} dtype: {valid_dataset[0][1].dtype}\\')\\n    print(f\\'Validation data targets shape: {valid_dataset[1].shape} dtype: {valid_dataset[1].dtype}\\')\\n    \\n    #Create model\\n    tf.keras.backend.clear_session()\\n    model = get_model()\\n    print(\\'Model prepared.\\')\\n    \\n    #Training model\\n    print(\\'Start training...\\')\\n    callbacks = [\\n    tf.keras.callbacks.ModelCheckpoint(f\"best_model_fold{fold}.h5\",\\n                                       monitor=\"val_loss\",\\n                                       mode=\"min\",\\n                                       save_best_only=True,\\n                                       verbose=1,\\n                                       save_weights_only=True,),\\n    tf.keras.callbacks.EarlyStopping(monitor=\\'val_loss\\', \\n                                     min_delta=1e-5, \\n                                     patience=3, \\n                                     verbose=1,\\n                                     mode=\\'min\\',)\\n    ]\\n    history = model.fit(x=train_dataset[0],\\n                        y=train_dataset[1],\\n                        validation_data=valid_dataset, \\n                        epochs=10,\\n                        shuffle=True,\\n                        batch_size=BATCH_SIZE,\\n                        callbacks=callbacks\\n                       )\\n    \\n    valid_rmses.append(np.min(history.history[\\'val_root_mean_squared_error\\']))\\n    print(\\'Training finished.\\')\\n    del train_dataset, valid_dataset, train_df, valid_df\\n    gc.collect()\\n'"},"metadata":{}}]},{"cell_type":"code","source":"#print(f'{len(valid_rmses)} Folds validation RMSE:\\n{valid_rmses}')\n#print(f'Local CV Average score: {np.mean(valid_rmses)}')","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:27.484916Z","iopub.execute_input":"2022-11-29T19:07:27.485543Z","iopub.status.idle":"2022-11-29T19:07:27.900694Z","shell.execute_reply.started":"2022-11-29T19:07:27.485504Z","shell.execute_reply":"2022-11-29T19:07:27.898174Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/2678172693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{len(valid_rmses)} Folds validation RMSE:\\n{valid_rmses}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Local CV Average score: {np.mean(valid_rmses)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'valid_rmses' is not defined"],"ename":"NameError","evalue":"name 'valid_rmses' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Inference and Submission\n\n","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:42.578739Z","iopub.execute_input":"2022-11-29T19:07:42.579093Z","iopub.status.idle":"2022-11-29T19:07:42.595858Z","shell.execute_reply.started":"2022-11-29T19:07:42.579060Z","shell.execute_reply":"2022-11-29T19:07:42.595008Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text\n0  0000C359D63E  when a person has no experience on a job their...\n1  000BAD50D026  Do you think students would benefit from being...\n2  00367BB2546B  Thomas Jefferson once states that \"it is wonde...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>when a person has no experience on a job their...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>Do you think students would benefit from being...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>Thomas Jefferson once states that \"it is wonde...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = deberta_encode(test_df['full_text'])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:42.799917Z","iopub.execute_input":"2022-11-29T19:07:42.800983Z","iopub.status.idle":"2022-11-29T19:07:42.818701Z","shell.execute_reply.started":"2022-11-29T19:07:42.800936Z","shell.execute_reply":"2022-11-29T19:07:42.817809Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# 5 Folds ensemble prediction","metadata":{}},{"cell_type":"code","source":"fold_preds = []\nfor fold in range(N_FOLD):\n    tf.keras.backend.clear_session()\n    model = get_model()\n    model.load_weights(f'/kaggle/input/feeback3-debertav3-base-weights-seed-opt/weights/best_model_fold{fold}.h5')\n    print(f'\\nFold {fold} inference...')\n    pred = model.predict(test_dataset, batch_size=BATCH_SIZE)\n    fold_preds.append(pred)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:07:43.016688Z","iopub.execute_input":"2022-11-29T19:07:43.017561Z","iopub.status.idle":"2022-11-29T19:09:55.154925Z","shell.execute_reply.started":"2022-11-29T19:07:43.017509Z","shell.execute_reply":"2022-11-29T19:09:55.153557Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nFold 0 inference...\n","output_type":"stream"},{"name":"stderr","text":"2022-11-29 19:08:02.349734: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"\nFold 1 inference...\n\nFold 2 inference...\n\nFold 3 inference...\n\nFold 4 inference...\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.mean(fold_preds, axis=0)\npreds = np.clip(preds, 1, 5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:09:55.157194Z","iopub.execute_input":"2022-11-29T19:09:55.157579Z","iopub.status.idle":"2022-11-29T19:09:55.167135Z","shell.execute_reply.started":"2022-11-29T19:09:55.157539Z","shell.execute_reply":"2022-11-29T19:09:55.165273Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.concat([test_df[['text_id']], pd.DataFrame(preds, columns=TARGET_COLS)], axis=1)\nsub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:09:55.169257Z","iopub.execute_input":"2022-11-29T19:09:55.170880Z","iopub.status.idle":"2022-11-29T19:09:55.185555Z","shell.execute_reply.started":"2022-11-29T19:09:55.170840Z","shell.execute_reply":"2022-11-29T19:09:55.184297Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T19:09:55.190412Z","iopub.execute_input":"2022-11-29T19:09:55.192896Z","iopub.status.idle":"2022-11-29T19:09:55.211847Z","shell.execute_reply.started":"2022-11-29T19:09:55.192857Z","shell.execute_reply":"2022-11-29T19:09:55.208865Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.893742  2.744203    3.051370     2.953171  2.598825   \n1  000BAD50D026  2.699825  2.488641    2.742798     2.388306  2.182445   \n2  00367BB2546B  3.577133  3.337628    3.551051     3.532416  3.350377   \n\n   conventions  \n0     2.630888  \n1     2.609449  \n2     3.215710  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.893742</td>\n      <td>2.744203</td>\n      <td>3.051370</td>\n      <td>2.953171</td>\n      <td>2.598825</td>\n      <td>2.630888</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.699825</td>\n      <td>2.488641</td>\n      <td>2.742798</td>\n      <td>2.388306</td>\n      <td>2.182445</td>\n      <td>2.609449</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.577133</td>\n      <td>3.337628</td>\n      <td>3.551051</td>\n      <td>3.532416</td>\n      <td>3.350377</td>\n      <td>3.215710</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}