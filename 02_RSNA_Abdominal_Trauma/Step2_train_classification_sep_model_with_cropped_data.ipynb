{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseonglee/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjunseonglee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/junseonglee/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "sys.path.append('./lib_models')\n",
    "\n",
    "\n",
    "#sys.path.append('')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.metrics\n",
    "import warnings\n",
    "import pydicom\n",
    "import dicomsdl\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import gzip\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch import nn\n",
    "from torchvision.io import read_image\n",
    "import segmentation_models_pytorch as smp\n",
    "import timm\n",
    "from timm.utils import AverageMeter\n",
    "from timm.models import resnet\n",
    "import timm_new\n",
    "\n",
    "from monai.transforms import Resize\n",
    "import  monai.transforms as transforms\n",
    "\n",
    "from timm.models.layers.conv2d_same import Conv2dSame\n",
    "from conv3d_same import Conv3dSame\n",
    "import wandb\n",
    "\n",
    "from FixRes.imnet_extract.pnasnet import pnasnet5large\n",
    "\n",
    "wandb.login(key = '585f58f321685308f7933861d9dde7488de0970b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = 'timm/resnet10t.c3_in1k'\n",
    "\n",
    "IS_WANDB = True\n",
    "PROJECT_NAME = 'RSNA_ABTD'\n",
    "GROUP_NAME= 'momdel_test'\n",
    "RUN_NAME=   f'{backbone}_Seg3d(Load)XEffNetb0-2d_1/4AvgPoolshrink'\n",
    "\n",
    "if not IS_WANDB:\n",
    "    PROJECT_NAME = 'Dummy_Project'\n",
    "\n",
    "BASE_PATH  = '/home/junseonglee/Desktop/01_codes/inputs/rsna-2023-abdominal-trauma-detection'\n",
    "TRAIN_PATH = f'{BASE_PATH}/train_images'\n",
    "DATA_PATH = f'{BASE_PATH}/3d_preprocessed'\n",
    "\n",
    "seg_inference_dir = f'{BASE_PATH}/seg_infer_results'\n",
    "cropped_img_dir   = f'{BASE_PATH}/3d_preprocessed_crop_ratio'\n",
    "\n",
    "if not os.path.isdir(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)\n",
    "\n",
    "RESOL = 160\n",
    "UP_RESOL = 128\n",
    "N_CHANNELS = 6\n",
    "BATCH_SIZE = 4\n",
    "ACCUM_STEPS = 2\n",
    "N_WORKERS  = 8\n",
    "LR = 0.0002\n",
    "N_EPOCHS = 200\n",
    "EARLY_STOP_COUNT = N_EPOCHS\n",
    "N_FOLDS  = 5\n",
    "SELECT_FOLD = 1\n",
    "N_PREPROCESS_CHUNKS = 12\n",
    "PCT_START = 0.3\n",
    "n_blocks = 4\n",
    "drop_rate = 0.2\n",
    "drop_path_rate = 0.2\n",
    "p_mixup = 0.0\n",
    "\n",
    "SEG_OUT_DIM = 5\n",
    "\n",
    "DROP_REGION= {'HOLES': [3, 20],\n",
    "                'SIZE': [5, 20],\n",
    "                'PROB': 0.5,\n",
    "                'FILL': (-3, 3)}\n",
    "\n",
    "wandb_config = {\n",
    "    'RESOL': RESOL,\n",
    "    'BACKBONE': backbone,\n",
    "    'N_CHANNELS': N_CHANNELS,\n",
    "    'N_EPOCHS': N_EPOCHS,\n",
    "    'N_FOLDS': N_FOLDS,\n",
    "    'EARLY_STOP_COUNT': EARLY_STOP_COUNT,\n",
    "    'BATCH_SIZE': BATCH_SIZE,    \n",
    "    'LR': LR,\n",
    "    'N_EPOCHS': N_EPOCHS,\n",
    "    'DROP_RATE': drop_rate,\n",
    "    'DROP_PATH_RATE': drop_path_rate,\n",
    "    'MIXUP_RATE': p_mixup,\n",
    "    'DROP_REGION': DROP_REGION,\n",
    "    'PCT_START': PCT_START\n",
    "}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_pnasnet5large():\n",
    "    #model= pnasnet5large(pretrained = False)\n",
    "    #pretrained_dict=torch.load(f'{BASE_PATH}/PNASNet.pth', map_location='cpu')['model']\n",
    "\n",
    "    #model_dict = model.state_dict()\n",
    "    ##for k in model_dict.keys():\n",
    "    #    if(('module.'+k) in pretrained_dict.keys()):\n",
    "    #        model_dict[k]=pretrained_dict.get(('module.'+k))\n",
    "    \n",
    "#    return model\n",
    "\n",
    "#model = load_pnasnet5large()\n",
    "#inputs = torch.zeros(1, 3, 128, 128)\n",
    "#outputs = model(inputs)\n",
    "#outputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([474, 480, 461, 471, 469, 466, 476, 480, 463, 471]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask related parameters\n",
    "# Order 0: Bowel, 1: left kidney, 2: right kidney, 3: liver, 4: spleen\n",
    "\n",
    "chan_keys = ['bowel', 'left_kidney', 'right_kidney', 'liver', 'spleen', 'total']\n",
    "chan_dict = {}\n",
    "for i in range(0, 6):\n",
    "    chan_dict[i] = chan_keys[i]\n",
    "\n",
    "train_meta_df = pd.read_csv(f'{BASE_PATH}/train_meta.csv')\n",
    "np.unique(train_meta_df['fold'].to_numpy(), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_injured_df = train_meta_df.loc[(train_meta_df['fold']!=SELECT_FOLD)& (train_meta_df['any_injury']==1)].copy()\n",
    "#train_meta_df = pd.concat([train_meta_df, train_injured_df])\n",
    "#len(train_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(name, data):\n",
    "    with gzip.open(name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def decompress(name):\n",
    "    with gzip.open(name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def compress_fast(name, data):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def decompress_fast(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_3d(module):\n",
    "\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    elif isinstance(module, Conv2dSame):\n",
    "        module_output = Conv3dSame(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timm3DModel(nn.Module):\n",
    "    def __init__(self, backbone, n_channels, n_labels, segtype='unet', pretrained=False):\n",
    "        super(Timm3DModel, self).__init__()\n",
    "        self.n_labels = n_labels\n",
    "        self.encoder = timm_new.create_model(\n",
    "            backbone,\n",
    "            in_chans=n_channels,\n",
    "            features_only=True,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, n_channels, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(5, 4, 2)\n",
    "        \n",
    "        [_.shape[1] for _ in g]\n",
    "        self.convs1x1 = nn.ModuleList()    \n",
    "        self.batchnorms = nn.ModuleList()    \n",
    "        self.batchnorms13 = nn.ModuleList()\n",
    "        for i in range(0, len(g)):\n",
    "            self.convs1x1.append(nn.Conv2d(g[i].shape[1], self.n_labels, 1))\n",
    "        del g\n",
    "        gc.collect()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        global_features = self.encoder(x)[:n_blocks]        \n",
    "        for i in range(0, len(global_features)):\n",
    "            #print(global_features[i].shape)\n",
    "            global_features[i] = self.convs1x1[i](global_features[i])\n",
    "        return global_features\n",
    "    \n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, in_chans = 1, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm_new.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            features_only=True,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, in_chans, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.unet.decoder.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], SEG_OUT_DIM, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "\n",
    "class CNNSegXClassifier(nn.Module):\n",
    "    def __init__(self, backbone = backbone, device = DEVICE):\n",
    "        super().__init__()\n",
    "        self.device = DEVICE\n",
    "        self.seg_model   = TimmSegModel(backbone)\n",
    "        self.seg_model = convert_3d(self.seg_model)\n",
    "        self.seg_model.load_state_dict(torch.load(f'{BASE_PATH}/seg_models_backup/231001_timm3d_res10tc_CV0.938.pt'))\n",
    "        \n",
    "        #self.pointwise_conv3d = nn.Conv3d(SEG_OUT_DIM, 1, kernel_size = (1, 1, 1))\n",
    "        #self.get_yz_conv3d = nn.Conv3d(SEG_OUT_DIM, 1, kernel_size = (1, 1, 1))\n",
    "        #self.get_zx_conv3d = nn.Conv3d(SEG_OUT_DIM, 1, kernel_size = (1, 1, 1))\n",
    "        #self.class_model = load_pnasnet5large() \n",
    "        self.class_model = timm_new.create_model('timm/tf_efficientnet_b0.ns_jft_in1k', pretrained = True,\n",
    "                                                drop_rate=0.5, drop_path_rate=0.5)\n",
    "        self.class_model.conv_stem = nn.Conv2d((SEG_OUT_DIM+1)*3, 32, kernel_size=(3, 3), stride = (2, 2), bias = False)\n",
    "        self.class_model.classifier = nn.Linear(in_features=1280, out_features=13, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = torch.cat([x_bowel, x_kidney_left, x_kidney_right, x_liver, x_spleen, x_total], dim = 1)\n",
    "        x_origin = torch.clone(x)\n",
    "        x = self.seg_model(x)\n",
    "        x = torch.cat([x, x_origin], dim = 1)\n",
    "        #x = self.pointwise_conv3d(x)\n",
    "        #x = nn.AvgPool3d((4, 4, 4))(x)\n",
    "        xy = torch.mean(x, dim = 2)\n",
    "        yz = torch.mean(x, dim = 4)\n",
    "        zx = torch.mean(x, dim = 3)\n",
    "        \n",
    "        slices_cat = torch.cat([xy, yz, zx], dim = 1)\n",
    "        output = self.class_model(slices_cat)\n",
    "        return output\n",
    "\n",
    "#inputs = torch.zeros(1, 1, 128, 128, 128)\n",
    "#model = CNNSegXClassifier()\n",
    "#outputs = model(inputs, inputs, inputs, inputs, inputs, inputs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalClassifier(nn.Module):\n",
    "    def __init__(self, device = DEVICE):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.model    = CNNSegXClassifier()\n",
    "        self.flatten  = nn.Flatten()\n",
    "        self.dropout  = nn.Dropout(p=0.5)\n",
    "        self.softmax  = nn.Softmax(dim=1)        \n",
    "        self.maxpool  = nn.MaxPool1d(5, 1)\n",
    "        \n",
    "        #self.lstm = nn.LSTM(input_size =32, hidden_size = 8, num_layers=5, batch_first=True, bidirectional=True, dropout = drop_rate)        \n",
    "        #self.head = nn.Linear(16, 13)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        labels    = self.model(x)\n",
    "\n",
    "        bowel_soft = self.softmax(labels[:,:2])\n",
    "        extrav_soft = self.softmax(labels[:,2:4])\n",
    "        kidney_soft = self.softmax(labels[:,4:7])\n",
    "        liver_soft = self.softmax(labels[:,7:10])\n",
    "        spleen_soft = self.softmax(labels[:,10:13])\n",
    "\n",
    "        any_in = torch.cat([1-bowel_soft[:,0:1], 1-extrav_soft[:,0:1], \n",
    "                            1-kidney_soft[:,0:1], 1-liver_soft[:,0:1], 1-spleen_soft[:,0:1]], dim = 1) \n",
    "        any_in = self.maxpool(any_in)\n",
    "        any_not_in = 1-any_in\n",
    "        any_in = torch.cat([any_not_in, any_in], dim = 1)\n",
    "\n",
    "        #any_in = torch.log(any_in + 1e-6)  # 1e-6은 0을 처리하기 위한 작은 값\n",
    "        return labels, any_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24942406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AbdominalClassifier()\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(get_n_params(model))\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones(2)\n",
    "weights[1] = 2\n",
    "crit_bowel  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "weights[1] = 6\n",
    "crit_extrav = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_any = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "\n",
    "weights = np.ones((3))\n",
    "weights[1] = 2\n",
    "weights[2] = 4\n",
    "crit_kidney = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_liver  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_spleen = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_one(tensor):\n",
    "    norm = torch.sum(tensor, 1)\n",
    "    for i in range(0, tensor.shape[1]):\n",
    "        tensor[:,i]/=norm\n",
    "    return tensor\n",
    "\n",
    "def apply_softmax_to_labels(X_out):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    X_out[:,:2]    = normalize_to_one(softmax(X_out[:,:2]))\n",
    "    X_out[:,2:4]   = normalize_to_one(softmax(X_out[:,2:4]))\n",
    "    X_out[:,4:7]   = normalize_to_one(softmax(X_out[:,4:7]))\n",
    "    X_out[:,7:10]  = normalize_to_one(softmax(X_out[:,7:10]))\n",
    "    X_out[:,10:13] = normalize_to_one(softmax(X_out[:,10:13]))\n",
    "\n",
    "    return X_out\n",
    "\n",
    "def calculate_score(X_outs, ys, step = 'train'):\n",
    "    X_outs = X_outs.astype(np.float64)\n",
    "    ys     = ys.astype(np.float64)\n",
    "\n",
    "    isnan_x = np.isnan(X_outs).astype(int)\n",
    "    isnan_y = np.isnan(ys).astype(int)\n",
    "    \n",
    "    if(np.max(isnan_x)>0):\n",
    "        print('xnan')\n",
    "    if(np.max(isnan_y)>0):\n",
    "        print('ynan')\n",
    "        \n",
    "    X_outs = np.nan_to_num(X_outs, nan = 0.0)\n",
    "        \n",
    "    #X_outs[:, 13:15] = nn.Softmax(dim=1)(torch.from_numpy(X_outs[:, 13:15])).numpy()\n",
    "    bowel_weights  =  ys[:,0] + 2*ys[:,1]\n",
    "    extrav_weights = ys[:,2] + 6*ys[:,3]\n",
    "    kidney_weights = ys[:,4] + 2*ys[:,5] + 4*ys[:,6]\n",
    "    liver_weights  = ys[:,7] + 2*ys[:,8] + 4*ys[:,9]\n",
    "    spleen_weights = ys[:,10] + 2*ys[:,11] + 4*ys[:,12]\n",
    "    any_in_weights = ys[:,13] + 6*ys[:,14]\n",
    "\n",
    "    bowel_loss  = sklearn.metrics.log_loss(ys[:,:2], X_outs[:,:2], sample_weight = bowel_weights.astype(np.float64))\n",
    "    extrav_loss = sklearn.metrics.log_loss(ys[:,2:4], X_outs[:,2:4], sample_weight = extrav_weights.astype(np.float64))\n",
    "    kidney_loss = sklearn.metrics.log_loss(ys[:,4:7], X_outs[:,4:7], sample_weight = kidney_weights.astype(np.float64))\n",
    "    liver_loss  = sklearn.metrics.log_loss(ys[:,7:10], X_outs[:,7:10], sample_weight = liver_weights.astype(np.float64))\n",
    "    spleen_loss = sklearn.metrics.log_loss(ys[:,10:13], X_outs[:,10:13], sample_weight = spleen_weights.astype(np.float64))\n",
    "    any_in_loss = sklearn.metrics.log_loss(ys[:,13:15], X_outs[:,13:15], sample_weight =  any_in_weights.astype(np.float64))\n",
    "    \n",
    "    avg_loss = (bowel_loss + extrav_loss + kidney_loss + liver_loss + spleen_loss + any_in_loss)/6\n",
    "\n",
    "    losses= {f'{step}_bowel_metric': bowel_loss, f'{step}_extrav_metric': extrav_loss, f'{step}_kidney_metric': kidney_loss,\n",
    "             f'{step}_liver_metric': liver_loss, f'{step}_spleen_metric': spleen_loss, f'{step}_any_in_metric': any_in_loss,\n",
    "             f'{step}_avg_metric': avg_loss}\n",
    "\n",
    "    wandb.log(losses)\n",
    "    return avg_loss\n",
    "\n",
    "def calculate_loss(X_out, X_any, y):\n",
    "    batch_size = X_out.shape[0]\n",
    "    bowel_loss  = crit_bowel(X_out[:,:2], y[:,:2])\n",
    "    extrav_loss = crit_extrav(X_out[:,2:4], y[:,2:4])\n",
    "    kidney_loss = crit_kidney(X_out[:,4:7], y[:,4:7])\n",
    "    liver_loss  = crit_liver(X_out[:,7:10], y[:,7:10])\n",
    "    spleen_loss = crit_spleen(X_out[:,10:13], y[:,10:13])\n",
    "    any_in_loss = crit_any(X_any,  torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1))\n",
    "    \n",
    "    avg_loss = (bowel_loss + extrav_loss + kidney_loss + liver_loss + spleen_loss + any_in_loss)/6\n",
    "    return bowel_loss, extrav_loss, kidney_loss, liver_loss, spleen_loss, any_in_loss, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(inputs, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(inputs.size(0))\n",
    "    shuffled_input = inputs[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    inputs = inputs * lam + shuffled_input * (1 - lam)\n",
    "    return inputs, truth, shuffled_labels, lam\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandFlipd(keys=['all'], prob=0.5, spatial_axis=0),    \n",
    "    transforms.RandFlipd(keys=['all'], prob=0.5, spatial_axis=1),\n",
    "    transforms.RandFlipd(keys=['all'], prob=0.5, spatial_axis=2),\n",
    "    #transforms.RandAffined(keys=chan_keys, translate_range=[int(x*y) for x, y in zip([RESOL, RESOL, RESOL], [0.3, 0.3, 0.3])], padding_mode='zeros', prob=0.7),\n",
    "    transforms.RandGridDistortiond(keys=['all'], prob=0.5, distort_limit=(-0.01, 0.01), mode=\"nearest\"),    \n",
    "])\n",
    "\n",
    "remain_transforms_train = transforms.Compose([\n",
    "])\n",
    "\n",
    "'''\n",
    "transforms.RandCoarseDropout(holes = DROP_REGION['HOLES'][0], max_holes = DROP_REGION['HOLES'][1],\n",
    "                        spatial_size = DROP_REGION['SIZE'][0]*np.ones(3, int), max_spatial_size =DROP_REGION['SIZE'][1]*np.ones(3, int), \n",
    "                        prob = DROP_REGION['PROB'], \n",
    "                        fill_value = DROP_REGION['FILL']),\n",
    "transforms.RandGaussianNoise(prob=0.2),\n",
    "transforms.RandBiasField(prob=0.2),\n",
    "transforms.RandAdjustContrast(prob=0.2),\n",
    "transforms.RandGaussianSmooth(prob=0.2),\n",
    "transforms.RandGaussianSharpen(prob=0.2),\n",
    "transforms.RandHistogramShift(prob=0.2),\n",
    "transforms.RandGibbsNoise(prob=0.2),\n",
    "transforms.RandKSpaceSpikeNoise(prob=0.2),\n",
    "transforms.RandRicianNoise(prob=0.2),    \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "transforms_common_preprocessing = transforms.Compose([\n",
    "    #transforms.HistogramNormalize(num_bins = 256, min = 0, max = 255)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalCTDataset(Dataset):\n",
    "    def __init__(self, meta_df, is_train = True, transform_set = None, remain_transforms_set = None):\n",
    "        self.meta_df = meta_df\n",
    "        self.is_train = is_train\n",
    "        self.transform_set = transform_set\n",
    "        self.remain_transforms_set = remain_transforms_set\n",
    "        self.data_3ds = []        \n",
    "        for i in tqdm(range(0, len(self.meta_df))):\n",
    "            tmp_data_3ds = {}\n",
    "            base_name = self.meta_df.iloc[i]['path']                        \n",
    "            tmp_data_3d = decompress(f'{base_name}').unsqueeze(0)\n",
    "            #tmp_data_3d = torch.from_numpy(tmp_data_3d)\n",
    "            tmp_data_3ds['all'] = tmp_data_3d            \n",
    "            self.data_3ds.append(tmp_data_3ds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta_df.iloc[idx]\n",
    "        label = row[['bowel_healthy','bowel_injury',\n",
    "                    'extravasation_healthy','extravasation_injury',\n",
    "                    'kidney_healthy','kidney_low','kidney_high',\n",
    "                    'liver_healthy','liver_low','liver_high',\n",
    "                    'spleen_healthy','spleen_low','spleen_high', 'any_injury']]\n",
    "        \n",
    "        data_3d = self.data_3ds[idx].copy()\n",
    "        \n",
    "        if self.is_train:\n",
    "            if self.transform_set is not None:\n",
    "                data_3d = self.transform_set(data_3d)\n",
    "\n",
    "            if self.remain_transforms_set is not None:   \n",
    "                for i in range(0, 1):\n",
    "                    data_3d['all'] = self.remain_transforms_set(data_3d['all'].type(torch.float32)).type(torch.float16)\n",
    "        \n",
    "        label = label.to_numpy().astype(np.float32)                    \n",
    "        label = torch.from_numpy(label)\n",
    "                    \n",
    "        return data_3d['all'], label        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_3d= torch.rand((6, 128, 128, 128))*0.5\n",
    "#data_3d = remain_transforms_train(data_3d)\n",
    "#torch.max(data_3d)\n",
    "#print(data_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, train_loader, scaler, scheduler, optimizer, epoch, accum_points, accum_scale):\n",
    "    train_meters = {'loss': AverageMeter()}\n",
    "    model.train()\n",
    "    X_outs=[]\n",
    "    ys=[]\n",
    "    accum_counter = 0\n",
    "    counter = 0\n",
    "    optimizer.zero_grad()\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        current_lr = float(scheduler.get_last_lr()[0])\n",
    "        \n",
    "        batch_size = X.shape[0]\n",
    "        with torch.cuda.amp.autocast(enabled=True):  \n",
    "            X_out, X_any  = model(X)\n",
    "            bowel_loss, extrav_loss, kidney_loss, liver_loss, spleen_loss, any_in_loss, avg_loss = calculate_loss(X_out, X_any, y)\n",
    "                \n",
    "            step = 'train'\n",
    "            wandb.log({ 'lr': current_lr,\n",
    "                        f'{step}_bowel_loss': bowel_loss.item(),\n",
    "                        f'{step}_extrav_loss': extrav_loss.item(),\n",
    "                        f'{step}_kidney_loss': kidney_loss.item(),\n",
    "                        f'{step}_liver_loss': liver_loss.item(),\n",
    "                        f'{step}_spleen_loss': spleen_loss.item(),\n",
    "                        f'{step}_any_loss': any_in_loss.item(),\n",
    "                        f'{step}_avg_loss': avg_loss.item()\n",
    "                        })\n",
    "            \n",
    "            scaler.scale(avg_loss/accum_scale[accum_counter]).backward()\n",
    "            if(counter==accum_points[accum_counter]):\n",
    "                scaler.step(optimizer)\n",
    "                scheduler.step()\n",
    "                scaler.update()    \n",
    "                accum_counter+=1                \n",
    "                optimizer.zero_grad()\n",
    "        counter+=1\n",
    "\n",
    "        #Metric calculation\n",
    "        y_any = torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1)    \n",
    "        X_out = apply_softmax_to_labels(X_out).detach().to('cpu').numpy()\n",
    "        X_any = X_any.detach().to('cpu').numpy()\n",
    "        X_out = np.hstack([X_out, X_any])\n",
    "        X_outs.append(X_out)\n",
    "\n",
    "        y     = y.to('cpu').numpy()[:,:-1]\n",
    "        y_any = y_any.to('cpu').numpy()\n",
    "        y     = np.hstack([y, y_any])\n",
    "        ys.append(y)\n",
    "\n",
    "        trn_loss = avg_loss.item()      \n",
    "        train_meters['loss'].update(trn_loss, n=batch_size)     \n",
    "        #pbar.set_description(f'Train loss: {trn_loss}')   \n",
    "        \n",
    "        \n",
    "    print('Epoch {:d} / trn/loss={:.4f}'.format(epoch+1, train_meters['loss'].avg))    \n",
    "\n",
    "    X_outs = np.vstack(X_outs) \n",
    "    ys     = np.vstack(ys)\n",
    "    metric = calculate_score(X_outs, ys, 'train')                 \n",
    "    print('Epoch {:d} / train/metric={:.4f}'.format(epoch+1, metric))   \n",
    "\n",
    "    del X, X_outs, y, ys, X_any\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()    \n",
    "    return scheduler, scaler, optimizer\n",
    "\n",
    "\n",
    "def valid_func(model, valid_loader, epoch):\n",
    "    X_outs=[]\n",
    "    ys=[]\n",
    "    model.eval()\n",
    "    for X, y in valid_loader:\n",
    "        batch_size = y.shape[0]\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)           \n",
    "        with torch.cuda.amp.autocast(enabled=True):                \n",
    "            with torch.no_grad():                 \n",
    "                X_out, X_any = model(X)                                          \n",
    "                y_any = torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1)              \n",
    "                X_out = apply_softmax_to_labels(X_out).to('cpu').numpy()\n",
    "\n",
    "                X_any = X_any.to('cpu').numpy()\n",
    "                X_out = np.hstack([X_out, X_any])\n",
    "                X_outs.append(X_out)\n",
    "\n",
    "                y     = y.to('cpu').numpy()[:,:-1]\n",
    "                y_any = y_any.to('cpu').numpy()\n",
    "                y     = np.hstack([y, y_any])\n",
    "                ys.append(y)\n",
    "\n",
    "    X_outs = np.vstack(X_outs) \n",
    "    ys     = np.vstack(ys)\n",
    "    metric = calculate_score(X_outs, ys, 'valid')                \n",
    "    print('Epoch {:d} / val/metric={:.4f}'.format(epoch+1, metric))           \n",
    "    \n",
    "    del X, X_outs, y, ys, X_any\n",
    "    gc.collect()        \n",
    "    torch.cuda.empty_cache()   \n",
    "    return metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/junseonglee/Desktop/01_codes/inputs/rsna-2023-abdominal-trauma-detection/wandb/run-20231015_134324-smv08egs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/junseonglee/RSNA_ABTD/runs/smv08egs' target=\"_blank\">timm/resnet10t.c3_in1k_Seg3d(Load)XEffNetb0-2d_1/4AvgPoolshrink</a></strong> to <a href='https://wandb.ai/junseonglee/RSNA_ABTD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/junseonglee/RSNA_ABTD' target=\"_blank\">https://wandb.ai/junseonglee/RSNA_ABTD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/junseonglee/RSNA_ABTD/runs/smv08egs' target=\"_blank\">https://wandb.ai/junseonglee/RSNA_ABTD/runs/smv08egs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4231/4231 [01:30<00:00, 46.96it/s]\n",
      "100%|██████████| 480/480 [00:10<00:00, 47.11it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / trn/loss=1.0306\n",
      "Epoch 1 / train/metric=0.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [10:09<33:40:04, 609.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / val/metric=0.6843\n",
      "Best val_metric 0.684292526795967 at epoch 1!\n",
      "Epoch 2 / trn/loss=0.8882\n",
      "Epoch 2 / train/metric=0.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [20:16<33:27:42, 608.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / val/metric=0.6314\n",
      "Best val_metric 0.6314384368990048 at epoch 2!\n",
      "Epoch 3 / trn/loss=0.8455\n",
      "Epoch 3 / train/metric=0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [30:25<33:17:48, 608.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / val/metric=0.6198\n",
      "Best val_metric 0.6197818946287917 at epoch 3!\n",
      "Epoch 4 / trn/loss=0.8321\n",
      "Epoch 4 / train/metric=0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [40:33<33:07:28, 608.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / val/metric=0.6127\n",
      "Best val_metric 0.6126641797367512 at epoch 4!\n",
      "Epoch 5 / trn/loss=0.8337\n",
      "Epoch 5 / train/metric=0.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [50:41<32:56:55, 608.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / val/metric=0.6228\n",
      "Epoch 6 / trn/loss=0.8300\n",
      "Epoch 6 / train/metric=0.5878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [1:00:50<32:47:12, 608.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / val/metric=0.6147\n",
      "Epoch 7 / trn/loss=0.8294\n",
      "Epoch 7 / train/metric=0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [1:10:58<32:36:37, 608.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / val/metric=0.6121\n",
      "Best val_metric 0.6120897740112475 at epoch 7!\n",
      "Epoch 8 / trn/loss=0.8263\n",
      "Epoch 8 / train/metric=0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [1:21:06<32:26:04, 608.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / val/metric=0.6037\n",
      "Best val_metric 0.6036770761945652 at epoch 8!\n",
      "Epoch 9 / trn/loss=0.8256\n",
      "Epoch 9 / train/metric=0.5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [1:31:14<32:15:34, 608.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / val/metric=0.6108\n",
      "Epoch 10 / trn/loss=0.8239\n",
      "Epoch 10 / train/metric=0.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [1:41:22<32:05:32, 608.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / val/metric=0.6154\n",
      "Epoch 11 / trn/loss=0.8193\n",
      "Epoch 11 / train/metric=0.5789\n",
      "Epoch 11 / val/metric=0.6022\n",
      "Best val_metric 0.6022414197959641 at epoch 11!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [1:51:30<31:55:42, 608.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / trn/loss=0.8220\n",
      "Epoch 12 / train/metric=0.5817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [2:01:39<31:45:49, 608.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 / val/metric=0.6039\n",
      "Epoch 13 / trn/loss=0.8200\n",
      "Epoch 13 / train/metric=0.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [2:11:47<31:35:56, 608.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 / val/metric=0.6035\n",
      "Epoch 14 / trn/loss=0.8166\n",
      "Epoch 14 / train/metric=0.5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [2:21:55<31:25:31, 608.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / val/metric=0.6006\n",
      "Best val_metric 0.6005825757437941 at epoch 14!\n",
      "Epoch 15 / trn/loss=0.8173\n",
      "Epoch 15 / train/metric=0.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [2:32:03<31:15:12, 608.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 / val/metric=0.6043\n",
      "Epoch 16 / trn/loss=0.8170\n",
      "Epoch 16 / train/metric=0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [2:42:11<31:04:55, 608.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 / val/metric=0.6058\n",
      "Epoch 17 / trn/loss=0.8160\n",
      "Epoch 17 / train/metric=0.5779\n",
      "Epoch 17 / val/metric=0.5991\n",
      "Best val_metric 0.5990852835852948 at epoch 17!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [2:52:19<30:54:44, 608.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / trn/loss=0.8071\n",
      "Epoch 18 / train/metric=0.5707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [3:02:27<30:44:30, 608.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / val/metric=0.5970\n",
      "Best val_metric 0.5969616775869079 at epoch 18!\n",
      "Epoch 19 / trn/loss=0.8100\n",
      "Epoch 19 / train/metric=0.5738\n",
      "Epoch 19 / val/metric=0.5919\n",
      "Best val_metric 0.5919044117864658 at epoch 19!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [3:12:36<30:34:52, 608.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 / trn/loss=0.8042\n",
      "Epoch 20 / train/metric=0.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [3:22:44<30:24:30, 608.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 / val/metric=0.6052\n",
      "Epoch 21 / trn/loss=0.8014\n",
      "Epoch 21 / train/metric=0.5669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [3:32:52<30:14:17, 608.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / val/metric=0.5870\n",
      "Best val_metric 0.5870213451793445 at epoch 21!\n",
      "Epoch 22 / trn/loss=0.8002\n",
      "Epoch 22 / train/metric=0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [3:43:00<30:03:45, 608.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 / val/metric=0.5933\n",
      "Epoch 23 / trn/loss=0.7985\n",
      "Epoch 23 / train/metric=0.5645\n",
      "Epoch 23 / val/metric=0.5754\n",
      "Best val_metric 0.575362821645878 at epoch 23!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [3:53:08<29:53:47, 608.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / trn/loss=0.7939\n",
      "Epoch 24 / train/metric=0.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [4:03:16<29:43:24, 607.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / val/metric=0.5903\n",
      "Epoch 25 / trn/loss=0.7893\n",
      "Epoch 25 / train/metric=0.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [4:13:24<29:33:28, 608.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / val/metric=0.5837\n",
      "Epoch 26 / trn/loss=0.7874\n",
      "Epoch 26 / train/metric=0.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [4:23:32<29:23:09, 607.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 / val/metric=0.5733\n",
      "Best val_metric 0.5733390585309759 at epoch 26!\n",
      "Epoch 27 / trn/loss=0.7923\n",
      "Epoch 27 / train/metric=0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [4:33:40<29:12:59, 607.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 / val/metric=0.5775\n",
      "Epoch 28 / trn/loss=0.7837\n",
      "Epoch 28 / train/metric=0.5536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [4:43:48<29:03:13, 608.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / val/metric=0.5902\n",
      "Epoch 29 / trn/loss=0.7800\n",
      "Epoch 29 / train/metric=0.5516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [4:53:56<28:53:02, 608.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 / val/metric=0.5772\n",
      "Epoch 30 / trn/loss=0.7715\n",
      "Epoch 30 / train/metric=0.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [5:04:04<28:42:45, 608.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 / val/metric=0.5896\n",
      "Epoch 31 / trn/loss=0.7688\n",
      "Epoch 31 / train/metric=0.5439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [5:14:13<28:33:08, 608.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / val/metric=0.5594\n",
      "Best val_metric 0.5593589104378524 at epoch 31!\n",
      "Epoch 32 / trn/loss=0.7634\n",
      "Epoch 32 / train/metric=0.5383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [5:24:21<28:22:46, 608.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 / val/metric=0.5445\n",
      "Best val_metric 0.5445229603486809 at epoch 32!\n",
      "Epoch 33 / trn/loss=0.7648\n",
      "Epoch 33 / train/metric=0.5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [5:34:29<28:12:28, 608.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 / val/metric=0.5663\n",
      "Epoch 34 / trn/loss=0.7529\n",
      "Epoch 34 / train/metric=0.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [5:44:37<28:02:25, 608.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 / val/metric=0.5623\n",
      "Epoch 35 / trn/loss=0.7484\n",
      "Epoch 35 / train/metric=0.5279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [5:54:45<27:52:07, 608.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / val/metric=0.5515\n",
      "Epoch 36 / trn/loss=0.7384\n",
      "Epoch 36 / train/metric=0.5186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [6:04:53<27:41:50, 607.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 / val/metric=0.5647\n",
      "Epoch 37 / trn/loss=0.7204\n",
      "Epoch 37 / train/metric=0.5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [6:15:01<27:32:06, 608.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 / val/metric=0.5853\n",
      "Epoch 38 / trn/loss=0.7204\n",
      "Epoch 38 / train/metric=0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [6:25:09<27:21:49, 608.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / val/metric=0.5551\n",
      "Epoch 39 / trn/loss=0.7115\n",
      "Epoch 39 / train/metric=0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [6:35:17<27:11:31, 608.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 / val/metric=0.5476\n",
      "Epoch 40 / trn/loss=0.7146\n",
      "Epoch 40 / train/metric=0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [6:45:25<27:01:32, 608.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 / val/metric=0.5278\n",
      "Best val_metric 0.5278089410977943 at epoch 40!\n",
      "Epoch 41 / trn/loss=0.7037\n",
      "Epoch 41 / train/metric=0.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [6:55:33<26:51:28, 608.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / val/metric=0.5504\n",
      "Epoch 42 / trn/loss=0.6957\n",
      "Epoch 42 / train/metric=0.4881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [7:05:42<26:41:36, 608.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / val/metric=0.5397\n",
      "Epoch 43 / trn/loss=0.6889\n",
      "Epoch 43 / train/metric=0.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [7:15:49<26:30:59, 608.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 / val/metric=0.5304\n",
      "Epoch 44 / trn/loss=0.6884\n",
      "Epoch 44 / train/metric=0.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [7:25:58<26:21:06, 608.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 / val/metric=0.5877\n",
      "Epoch 45 / trn/loss=0.6733\n",
      "Epoch 45 / train/metric=0.4681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [7:36:05<26:10:36, 607.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / val/metric=0.5708\n",
      "Epoch 46 / trn/loss=0.6736\n",
      "Epoch 46 / train/metric=0.4681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [7:46:13<26:00:16, 607.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 / val/metric=0.5413\n",
      "Epoch 47 / trn/loss=0.6735\n",
      "Epoch 47 / train/metric=0.4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [7:56:21<25:50:12, 607.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 / val/metric=0.5463\n",
      "Epoch 48 / trn/loss=0.6652\n",
      "Epoch 48 / train/metric=0.4613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [8:06:29<25:39:48, 607.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / val/metric=0.5779\n",
      "Epoch 49 / trn/loss=0.6507\n",
      "Epoch 49 / train/metric=0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [8:16:36<25:29:43, 607.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 / val/metric=0.5654\n",
      "Epoch 50 / trn/loss=0.6436\n",
      "Epoch 50 / train/metric=0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [8:26:44<25:19:33, 607.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 / val/metric=0.5176\n",
      "Best val_metric 0.5176499287767846 at epoch 50!\n",
      "Epoch 51 / trn/loss=0.6423\n",
      "Epoch 51 / train/metric=0.4443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [8:36:52<25:09:43, 607.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / val/metric=0.5320\n",
      "Epoch 52 / trn/loss=0.6286\n",
      "Epoch 52 / train/metric=0.4329\n",
      "Epoch 52 / val/metric=0.5077\n",
      "Best val_metric 0.5076705434563363 at epoch 52!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [8:47:01<25:00:00, 608.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 / trn/loss=0.6262\n",
      "Epoch 53 / train/metric=0.4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [8:57:09<24:49:55, 608.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 / val/metric=0.5693\n",
      "Epoch 54 / trn/loss=0.6138\n",
      "Epoch 54 / train/metric=0.4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [9:07:18<24:40:17, 608.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 / val/metric=0.5408\n",
      "Epoch 55 / trn/loss=0.6098\n",
      "Epoch 55 / train/metric=0.4172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [9:17:26<24:29:51, 608.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / val/metric=0.5158\n",
      "Epoch 56 / trn/loss=0.5953\n",
      "Epoch 56 / train/metric=0.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [9:27:34<24:19:34, 608.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 / val/metric=0.5216\n",
      "Epoch 57 / trn/loss=0.5855\n",
      "Epoch 57 / train/metric=0.3955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [9:37:42<24:09:41, 608.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 / val/metric=0.5728\n",
      "Epoch 58 / trn/loss=0.5809\n",
      "Epoch 58 / train/metric=0.3921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [9:47:50<23:59:20, 608.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / val/metric=0.6308\n",
      "Epoch 59 / trn/loss=0.5733\n",
      "Epoch 59 / train/metric=0.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [9:57:58<23:49:00, 608.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 / val/metric=0.5568\n",
      "Epoch 60 / trn/loss=0.5680\n",
      "Epoch 60 / train/metric=0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [10:08:06<23:38:55, 608.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 / val/metric=0.5507\n",
      "Epoch 61 / trn/loss=0.5615\n",
      "Epoch 61 / train/metric=0.3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [10:18:14<23:28:34, 608.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 / val/metric=0.5957\n",
      "Epoch 62 / trn/loss=0.5530\n",
      "Epoch 62 / train/metric=0.3701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [10:28:22<23:18:17, 607.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / val/metric=0.6253\n",
      "Epoch 63 / trn/loss=0.5343\n",
      "Epoch 63 / train/metric=0.3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [10:38:30<23:08:11, 607.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 / val/metric=0.5794\n",
      "Epoch 64 / trn/loss=0.5309\n",
      "Epoch 64 / train/metric=0.3507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [10:48:38<22:58:21, 608.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 / val/metric=0.6244\n",
      "Epoch 65 / trn/loss=0.5320\n",
      "Epoch 65 / train/metric=0.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [10:58:46<22:48:08, 608.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / val/metric=0.5923\n",
      "Epoch 66 / trn/loss=0.5158\n",
      "Epoch 66 / train/metric=0.3408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [11:08:54<22:37:55, 608.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 / val/metric=0.5819\n",
      "Epoch 67 / trn/loss=0.5105\n",
      "Epoch 67 / train/metric=0.3340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [11:19:02<22:27:45, 608.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 / val/metric=0.6615\n",
      "Epoch 68 / trn/loss=0.5064\n",
      "Epoch 68 / train/metric=0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [11:29:11<22:18:07, 608.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / val/metric=0.5884\n",
      "Epoch 69 / trn/loss=0.4909\n",
      "Epoch 69 / train/metric=0.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [11:39:20<22:08:16, 608.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / val/metric=0.7044\n",
      "Epoch 70 / trn/loss=0.4859\n",
      "Epoch 70 / train/metric=0.3128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [11:49:28<21:57:53, 608.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 / val/metric=0.6857\n",
      "Epoch 71 / trn/loss=0.4857\n",
      "Epoch 71 / train/metric=0.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [11:59:36<21:47:34, 608.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 / val/metric=0.5923\n",
      "Epoch 72 / trn/loss=0.4869\n",
      "Epoch 72 / train/metric=0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [12:09:45<21:37:56, 608.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / val/metric=0.6215\n",
      "Epoch 73 / trn/loss=0.4609\n",
      "Epoch 73 / train/metric=0.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [12:19:53<21:27:35, 608.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 / val/metric=0.6916\n",
      "Epoch 74 / trn/loss=0.4571\n",
      "Epoch 74 / train/metric=0.2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [12:30:01<21:17:22, 608.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 / val/metric=0.6626\n",
      "Epoch 75 / trn/loss=0.4671\n",
      "Epoch 75 / train/metric=0.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [12:40:09<21:07:11, 608.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / val/metric=0.6300\n",
      "Epoch 76 / trn/loss=0.4497\n",
      "Epoch 76 / train/metric=0.2823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [12:50:17<20:56:47, 608.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 / val/metric=0.6557\n",
      "Epoch 77 / trn/loss=0.4397\n",
      "Epoch 77 / train/metric=0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [13:00:25<20:46:50, 608.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 / val/metric=0.7488\n",
      "Epoch 78 / trn/loss=0.4237\n",
      "Epoch 78 / train/metric=0.2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [13:10:33<20:36:35, 608.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / val/metric=0.7297\n",
      "Epoch 79 / trn/loss=0.4295\n",
      "Epoch 79 / train/metric=0.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [13:20:42<20:26:34, 608.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / val/metric=0.7116\n",
      "Epoch 80 / trn/loss=0.4187\n",
      "Epoch 80 / train/metric=0.2573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [13:30:50<20:16:25, 608.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 / val/metric=0.6320\n",
      "Epoch 81 / trn/loss=0.4119\n",
      "Epoch 81 / train/metric=0.2511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [13:40:59<20:06:30, 608.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 / val/metric=0.6689\n",
      "Epoch 82 / trn/loss=0.4076\n",
      "Epoch 82 / train/metric=0.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [13:51:07<19:56:26, 608.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / val/metric=0.7004\n",
      "Epoch 83 / trn/loss=0.4097\n",
      "Epoch 83 / train/metric=0.2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [14:01:15<19:46:02, 608.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 / val/metric=0.6929\n",
      "Epoch 84 / trn/loss=0.4036\n",
      "Epoch 84 / train/metric=0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/200 [14:11:23<19:35:46, 608.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 / val/metric=0.7678\n",
      "Epoch 85 / trn/loss=0.3854\n",
      "Epoch 85 / train/metric=0.2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 85/200 [14:21:31<19:25:25, 608.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / val/metric=0.6852\n",
      "Epoch 86 / trn/loss=0.3927\n",
      "Epoch 86 / train/metric=0.2358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86/200 [14:31:39<19:15:20, 608.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 / val/metric=0.7324\n",
      "Epoch 87 / trn/loss=0.3767\n",
      "Epoch 87 / train/metric=0.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [14:41:47<19:05:07, 608.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 / val/metric=0.7453\n",
      "Epoch 88 / trn/loss=0.3714\n",
      "Epoch 88 / train/metric=0.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 88/200 [14:51:56<18:55:25, 608.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 / val/metric=0.8163\n",
      "Epoch 89 / trn/loss=0.3671\n",
      "Epoch 89 / train/metric=0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/200 [15:02:04<18:45:35, 608.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / val/metric=0.7971\n",
      "Epoch 90 / trn/loss=0.3629\n",
      "Epoch 90 / train/metric=0.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [15:12:13<18:35:16, 608.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 / val/metric=0.7774\n",
      "Epoch 91 / trn/loss=0.3627\n",
      "Epoch 91 / train/metric=0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [15:22:21<18:24:57, 608.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 / val/metric=0.7543\n",
      "Epoch 92 / trn/loss=0.3399\n",
      "Epoch 92 / train/metric=0.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92/200 [15:32:29<18:14:59, 608.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / val/metric=0.7477\n",
      "Epoch 93 / trn/loss=0.3474\n",
      "Epoch 93 / train/metric=0.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [15:42:37<18:04:42, 608.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 / val/metric=0.8789\n",
      "Epoch 94 / trn/loss=0.3324\n",
      "Epoch 94 / train/metric=0.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94/200 [15:52:45<17:54:20, 608.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 / val/metric=0.7984\n",
      "Epoch 95 / trn/loss=0.3374\n",
      "Epoch 95 / train/metric=0.1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/200 [16:02:53<17:44:16, 608.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / val/metric=0.8560\n",
      "Epoch 96 / trn/loss=0.3273\n",
      "Epoch 96 / train/metric=0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/200 [16:13:01<17:34:02, 608.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 / val/metric=0.8389\n",
      "Epoch 97 / trn/loss=0.3195\n",
      "Epoch 97 / train/metric=0.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [16:23:09<17:23:54, 608.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 / val/metric=0.8642\n",
      "Epoch 98 / trn/loss=0.3179\n",
      "Epoch 98 / train/metric=0.1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98/200 [16:33:18<17:13:54, 608.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 / val/metric=0.8984\n",
      "Epoch 99 / trn/loss=0.3170\n",
      "Epoch 99 / train/metric=0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [16:43:26<17:03:47, 608.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / val/metric=0.8899\n",
      "Epoch 100 / trn/loss=0.2991\n",
      "Epoch 100 / train/metric=0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [16:53:34<16:53:32, 608.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 / val/metric=0.9285\n",
      "Epoch 101 / trn/loss=0.3074\n",
      "Epoch 101 / train/metric=0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [17:03:42<16:43:32, 608.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 / val/metric=0.8154\n",
      "Epoch 102 / trn/loss=0.3061\n",
      "Epoch 102 / train/metric=0.1585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/200 [17:13:50<16:33:07, 608.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / val/metric=0.9970\n",
      "Epoch 103 / trn/loss=0.3036\n",
      "Epoch 103 / train/metric=0.1588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [17:23:58<16:22:56, 608.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 / val/metric=0.8862\n",
      "Epoch 104 / trn/loss=0.2936\n",
      "Epoch 104 / train/metric=0.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 104/200 [17:34:06<16:12:40, 607.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 / val/metric=0.9802\n",
      "Epoch 105 / trn/loss=0.2888\n",
      "Epoch 105 / train/metric=0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [17:44:13<16:02:31, 607.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / val/metric=0.8652\n",
      "Epoch 106 / trn/loss=0.2842\n",
      "Epoch 106 / train/metric=0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [17:54:21<15:52:19, 607.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 / val/metric=1.0182\n",
      "Epoch 107 / trn/loss=0.2725\n",
      "Epoch 107 / train/metric=0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [18:04:29<15:42:12, 607.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 / val/metric=0.9878\n",
      "Epoch 108 / trn/loss=0.2734\n",
      "Epoch 108 / train/metric=0.1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108/200 [18:14:37<15:32:04, 607.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 / val/metric=0.9758\n",
      "Epoch 109 / trn/loss=0.2683\n",
      "Epoch 109 / train/metric=0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [18:24:46<15:22:25, 608.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / val/metric=0.9741\n",
      "Epoch 110 / trn/loss=0.2647\n",
      "Epoch 110 / train/metric=0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [18:34:54<15:12:18, 608.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 / val/metric=1.0009\n",
      "Epoch 111 / trn/loss=0.2578\n",
      "Epoch 111 / train/metric=0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [18:45:03<15:02:16, 608.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 / val/metric=1.1161\n",
      "Epoch 112 / trn/loss=0.2475\n",
      "Epoch 112 / train/metric=0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 112/200 [18:55:10<14:51:58, 608.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / val/metric=1.0938\n"
     ]
    }
   ],
   "source": [
    "model = AbdominalClassifier()\n",
    "model.to(DEVICE)\n",
    "\n",
    "wandb.init(\n",
    "    config = wandb_config,\n",
    "    project= PROJECT_NAME,\n",
    "    group  = GROUP_NAME,\n",
    "    name   = RUN_NAME,\n",
    "    dir    = BASE_PATH)\n",
    "\n",
    "backbone = backbone.replace('/', '_')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']!=SELECT_FOLD], is_train = True, transform_set  = transforms_train, \n",
    "                                        remain_transforms_set = None)\n",
    "    valid_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']==SELECT_FOLD], is_train = False, transform_set = None,\n",
    "                                        remain_transforms_set = None)\n",
    "    \n",
    "    train_loader = DataLoader(dataset = train_dataset, shuffle = True, batch_size = BATCH_SIZE, pin_memory = True, \n",
    "                            num_workers = N_WORKERS*2, drop_last = False)\n",
    "\n",
    "    valid_loader = DataLoader(dataset = valid_dataset, shuffle = False, batch_size = BATCH_SIZE, pin_memory = True, \n",
    "                            num_workers = N_WORKERS, drop_last = False)     \n",
    "    \n",
    "    ttl_iters = N_EPOCHS * len(train_loader)\n",
    "    \n",
    "    #gradient accumulation for stability of the training\n",
    "    accum_len = int(np.ceil(len(train_loader)/ACCUM_STEPS)+0.001)\n",
    "    accum_points = np.zeros(accum_len, int)\n",
    "    accum_scale  = np.zeros(accum_len, int)\n",
    "    \n",
    "    prev_step = -1\n",
    "    for i in range(0, accum_len):\n",
    "        accum_points[i] = min(prev_step+ACCUM_STEPS, len(train_loader)-1)\n",
    "        accum_scale[i]  = accum_points[i] - prev_step\n",
    "        prev_step = accum_points[i]\n",
    "\n",
    "    #Scheduler & optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = LR, weight_decay = 0.001)\n",
    "    n_batch_iters = int(np.ceil(len(train_loader)/ACCUM_STEPS)+0.001)\n",
    "    #scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR, pct_start= PCT_START,\n",
    "                                                    steps_per_epoch= n_batch_iters, epochs = N_EPOCHS)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "    val_metrics = np.ones(N_EPOCHS)*100\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    for epoch in tqdm(range(0, N_EPOCHS), leave = False):     \n",
    "\n",
    "        scheduler, scaler, optimizer = train_func(model, train_loader, scaler, scheduler, optimizer, epoch, accum_points, accum_scale)\n",
    "        metric                       = valid_func(model, valid_loader, epoch)\n",
    "        \n",
    "        #Save the best model    \n",
    "        if(metric < np.min(val_metrics)):\n",
    "            try:\n",
    "                os.makedirs(f'{BASE_PATH}/weights')\n",
    "            except:\n",
    "                a = 1\n",
    "            best_metric = metric\n",
    "            print(f'Best val_metric {best_metric} at epoch {epoch+1}!')\n",
    "            torch.save(model.state_dict(), f'{BASE_PATH}/weights/{backbone}_lr{LR}_epochs_{N_EPOCHS}_resol{UP_RESOL}_batch{BATCH_SIZE*ACCUM_STEPS}_best.pt') \n",
    "            if(metric < 0.48):\n",
    "                torch.save(model.state_dict(), f'{BASE_PATH}/weights/{backbone}_lr{LR}_epochs_{N_EPOCHS}_resol{UP_RESOL}_batch{BATCH_SIZE*ACCUM_STEPS}_{metric}.pt') \n",
    "            not_improve_counter=0\n",
    "            val_metrics[epoch] = metric\n",
    "            continue                    \n",
    "        val_metrics[epoch] = metric                        \n",
    "        \n",
    "        #Early stopping\n",
    "        not_improve_counter+=1\n",
    "        if(not_improve_counter == EARLY_STOP_COUNT):\n",
    "            print(f'Not improved for {not_improve_counter} epochs, terminate the train')\n",
    "            break\n",
    "wandb.log({'best_total_log_loss': best_metric})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this cell to fininsh the wandb run when you stopped training.+\n",
    "import wandb\n",
    "try: \n",
    "    wandb.log(\n",
    "        {'best_total_log_loss': best_metric})\n",
    "    wandb.finish()\n",
    "    \n",
    "except: \n",
    "    print('Wandb is already finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 23561\n",
    "train_meta_df[train_meta_df['patient_id']==ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['patient_id']==ind], is_train = False, transform_set = None,\n",
    "                                    remain_transforms_set = None)\n",
    "\n",
    "valid_loader = DataLoader(dataset = valid_dataset, shuffle = False, batch_size = BATCH_SIZE, pin_memory = False, \n",
    "                        num_workers = N_WORKERS, drop_last = False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outs=[]\n",
    "ys=[]\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(f'{BASE_PATH}/weights/231003_resnet10t_dicomO_std_CV0.485.pt'))\n",
    "for X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, y in valid_loader:\n",
    "    batch_size = y.shape[0]\n",
    "    X_bowel, X_lkid, X_rkid = X_bowel.to(DEVICE), X_lkid.to(DEVICE), X_rkid.to(DEVICE)\n",
    "    X_liv, X_spl, X_tot     = X_liv.to(DEVICE), X_spl.to(DEVICE), X_tot.to(DEVICE)\n",
    "    y = y.to(DEVICE)           \n",
    "    with torch.cuda.amp.autocast(enabled=True):                \n",
    "        with torch.no_grad():                 \n",
    "            X_out, X_any = model(X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot)                                          \n",
    "            y_any = torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1)              \n",
    "            X_out = apply_softmax_to_labels(X_out).to('cpu').numpy()\n",
    "\n",
    "            X_any = X_any.to('cpu').numpy()\n",
    "            X_out = np.hstack([X_out, X_any])\n",
    "            X_outs.append(X_out)\n",
    "\n",
    "            y     = y.to('cpu').numpy()[:,:-1]\n",
    "            y_any = y_any.to('cpu').numpy()\n",
    "            y     = np.hstack([y, y_any])\n",
    "            ys.append(y)\n",
    "\n",
    "X_outs = np.vstack(X_outs) \n",
    "ys     = np.vstack(ys)\n",
    "#metric = calculate_score(X_outs, ys, 'valid')                      \n",
    "\n",
    "del X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, X_any\n",
    "gc.collect()        \n",
    "torch.cuda.empty_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(X_outs, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
