{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch import nn\n",
    "from resnet3d import generate_model\n",
    "from timm.utils import AverageMeter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/junseonglee/01_codes/input/rsna-2023-abdominal-trauma-detection'\n",
    "RESOL = 256\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.00001\n",
    "N_EPOCHS = 30\n",
    "train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "train_meta_df = pd.read_csv(f'{BASE_PATH}/train_meta.csv')\n",
    "train_df = train_df.sort_values(by=['patient_id'])\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#DEVICE = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AbdominalCTDataset(Dataset):\n",
    "    def __init__(self, meta_df):\n",
    "        self.meta_df = meta_df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta_df.iloc[idx]\n",
    "        label = row[['bowel_healthy','bowel_injury',\n",
    "                    'extravasation_healthy','extravasation_injury',\n",
    "                    'kidney_healthy','kidney_low','kidney_high',\n",
    "                    'liver_healthy','liver_low','liver_high',\n",
    "                    'spleen_healthy','spleen_low','spleen_high', 'any_injury']]\n",
    "        data_3d = cv2.imread(row['path'], cv2.IMREAD_GRAYSCALE)\n",
    "        data_3d = cv2.equalizeHist(data_3d)\n",
    "        data_3d = data_3d.reshape(1, RESOL, RESOL, RESOL).astype(float)  # channel, 3D\n",
    "        #avg std\n",
    "        data_3d -=47.5739\n",
    "        data_3d /=34.6175\n",
    "        data_3d = torch.from_numpy(data_3d.astype(np.float32))\n",
    "        label = label.to_numpy().astype(np.float32)\n",
    "                \n",
    "        #any_injury = label[-1]\n",
    "        #nu_any_injury = np.zeros(2)\n",
    "        #nu_any_injury[int(any_injury)]= 1\n",
    "        \n",
    "        #label = np.hstack([label[:-1], nu_any_injury])\n",
    "        label = torch.from_numpy(label)\n",
    "        return data_3d, label        \n",
    "\n",
    "train_dataset = AbdominalCTDataset(train_meta_df)\n",
    "data_3d, label = train_dataset[0]\n",
    "print(label)\n",
    "\n",
    "del train_dataset, data_3d, label\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#normalizatino parameter\\ntrain_dataset = AbdominalCTDataset(train_meta_df)\\ndata_3d, label = train_dataset[0]\\n\\navgs = np.zeros(len(train_dataset))\\nstds = np.zeros(len(train_dataset))\\nfor i in tqdm(range(0, len(train_dataset))):\\n    data_3d, label = train_dataset[i]\\n    data_3d = data_3d.numpy()\\n    avgs[i] = np.average(data_3d)\\n    stds[i] = np.std(data_3d)\\nprint(np.average(avgs))\\nprint(np.average(stds))    \\n\\ndel train_dataset, data_3d, label, avgs, stds\\ngc.collect()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#normalizatino parameter\n",
    "train_dataset = AbdominalCTDataset(train_meta_df)\n",
    "data_3d, label = train_dataset[0]\n",
    "\n",
    "avgs = np.zeros(len(train_dataset))\n",
    "stds = np.zeros(len(train_dataset))\n",
    "for i in tqdm(range(0, len(train_dataset))):\n",
    "    data_3d, label = train_dataset[i]\n",
    "    data_3d = data_3d.numpy()\n",
    "    avgs[i] = np.average(data_3d)\n",
    "    stds[i] = np.std(data_3d)\n",
    "print(np.average(avgs))\n",
    "print(np.average(stds))    \n",
    "\n",
    "del train_dataset, data_3d, label, avgs, stds\n",
    "gc.collect()\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalClassifier(nn.Module):\n",
    "    def __init__(self, model_depth, device = DEVICE):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.resnet3d = generate_model(model_depth = model_depth, n_input_channels = 1)\n",
    "        self.flatten  = nn.Flatten()\n",
    "        self.dropout  = nn.Dropout(p=0.5)\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "        size_res_out  = 56832\n",
    "        self.fc_bowel = nn.Linear(size_res_out, 2)\n",
    "        self.fc_extrav= nn.Linear(size_res_out, 2)\n",
    "        self.fc_kidney= nn.Linear(size_res_out, 3)\n",
    "        self.fc_liver = nn.Linear(size_res_out, 3)\n",
    "        self.fc_spleen= nn.Linear(size_res_out, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet3d(x)\n",
    "        for i in range(0, 4):\n",
    "            x[i] = self.flatten(x[i])\n",
    "        x = torch.cat(x, axis = 1)\n",
    "        x     = self.dropout(x)\n",
    "        bowel = self.fc_bowel(x)\n",
    "        extrav= self.fc_extrav(x)\n",
    "        kidney= self.fc_kidney(x)\n",
    "        liver = self.fc_liver(x)\n",
    "        spleen= self.fc_spleen(x)\n",
    "\n",
    "        labels = torch.cat([bowel, extrav, kidney, liver, spleen], dim = 1)\n",
    "\n",
    "        bowel_soft = self.softmax(bowel)\n",
    "        extrav_soft = self.softmax(extrav)\n",
    "        kidney_soft = self.softmax(kidney)\n",
    "        liver_soft = self.softmax(liver)\n",
    "        spleen_soft = self.softmax(spleen)\n",
    "\n",
    "        any_in = torch.cat([1-bowel_soft[:,0:1], 1-extrav_soft[:,0:1], \n",
    "                            1-kidney_soft[:,0:1], 1-liver_soft[:,0:1], 1-spleen_soft[:,0:1]], dim = 1) \n",
    "        any_in = torch.max(any_in, dim = 1).values\n",
    "        \n",
    "        return labels, any_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15094349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AbdominalClassifier(10)\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(get_n_params(model))\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']!=0])\n",
    "valid_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']==0])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, shuffle = True, batch_size = BATCH_SIZE, pin_memory = True, \n",
    "                          num_workers = 8, drop_last = True)\n",
    "\n",
    "valid_loader = DataLoader(dataset = valid_dataset, shuffle = False, batch_size = BATCH_SIZE, pin_memory = True, \n",
    "                          num_workers = 8, drop_last = False)                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AbdominalClassifier(18)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = LR)\n",
    "ttl_iters = N_EPOCHS * len(train_loader)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
    "\n",
    "\n",
    "weights = np.ones(2)\n",
    "weights[1] = 2\n",
    "crit_bowel  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "weights[1] = 6\n",
    "crit_extrav = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "#crit_any_in = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "\n",
    "weights = np.ones((3))\n",
    "weights[1] = 2\n",
    "weights[2] = 4\n",
    "crit_kidney = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_liver  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_spleen = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "\n",
    "weights = np.ones((BATCH_SIZE))*6\n",
    "crit_any = nn.BCELoss(weight = torch.from_numpy(weights).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de55a10f6fd45e18d4f3bacf6e0c00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/945 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseonglee/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/nn/modules/conv.py:608: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [4, 1] doesn't match the broadcast shape [4, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m crit_liver(X_out[:,\u001b[39m7\u001b[39m:\u001b[39m10\u001b[39m], y[:,\u001b[39m7\u001b[39m:\u001b[39m10\u001b[39m])\n\u001b[1;32m     20\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m crit_spleen(X_out[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m], y[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m crit_any(X_any,  y[:,\u001b[39m13\u001b[39;49m:\u001b[39m14\u001b[39;49m])\n\u001b[1;32m     23\u001b[0m scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m scaler\u001b[39m.\u001b[39mstep(optimizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/nn/functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3096\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3098\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [4, 1] doesn't match the broadcast shape [4, 4]"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "val_losses = np.ones(N_EPOCHS)*100\n",
    "for epoch in range(0, N_EPOCHS):\n",
    "    train_meters = {'loss': AverageMeter()}\n",
    "    val_meters   = {'loss': AverageMeter()}\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, leave=False)\n",
    "    for X, y in pbar:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            X_out, X_any  = model(X)\n",
    "\n",
    "            loss  = crit_bowel(X_out[:,:2], y[:,:2])\n",
    "            loss += crit_extrav(X_out[:,2:4], y[:,2:4])\n",
    "            loss += crit_kidney(X_out[:,4:7], y[:,4:7])\n",
    "            loss += crit_liver(X_out[:,7:10], y[:,7:10])\n",
    "            loss += crit_spleen(X_out[:,10:13], y[:,10:13])\n",
    "            loss += crit_any(X_any,  y[:,13:14])\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scheduler.step()\n",
    "            scaler.update()          \n",
    "\n",
    "        trn_loss = loss.item()      \n",
    "        train_meters['loss'].update(trn_loss, n=X.size(0))     \n",
    "        pbar.set_description(f'Train loss: {trn_loss}')\n",
    "        #print(trn_loss)     \n",
    "    print('Epoch {:d} / trn/loss={:.4f}'.format(epoch+1, train_meters['loss'].avg))    \n",
    "\n",
    "    model.eval()\n",
    "    for X, y in tqdm(valid_loader, leave=False):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=False):        \n",
    "            with torch.no_grad(): \n",
    "                X_out, X_any = model(X)\n",
    "                #X_out = torch.log(X_out)\n",
    "                loss  = crit_bowel(X_out[:,:2], y[:,:2])\n",
    "                loss += crit_extrav(X_out[:,2:4], y[:,2:4])\n",
    "                loss += crit_kidney(X_out[:,4:7], y[:,4:7])\n",
    "                loss += crit_liver(X_out[:,7:10], y[:,7:10])\n",
    "                loss += crit_spleen(X_out[:,10:13], y[:,10:13])\n",
    "                loss += crit_any(X_any,  y[:,13:14])                \n",
    "                #how about connecting it to other injuries?\n",
    "                #loss += crit_any_in(X_out[:,13:15], y[:,13:15])\n",
    "                val_loss = loss.item()\n",
    "        val_meters['loss'].update(val_loss, n=X.size(0))\n",
    "    print('Epoch {:d} / val/loss={:.4f}'.format(epoch+1, val_meters['loss'].avg))\n",
    "    #Save the best model\n",
    "    if(val_meters['loss'].avg < np.min(val_losses)):\n",
    "        try:\n",
    "            os.makedirs(f'{BASE_PATH}/weights')\n",
    "        except:\n",
    "            a = 1\n",
    "        best_loss = val_meters['loss'].avg\n",
    "        print(f'Best val_loss {best_loss} at epoch {epoch+1}!')\n",
    "        torch.save(model, f'{BASE_PATH}/weights/best.pt')    \n",
    "    \n",
    "    val_losses[epoch] = val_meters['loss'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
