{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch import nn\n",
    "from resnet3d import generate_model\n",
    "from timm.utils import AverageMeter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/junseonglee/01_codes/input/rsna-2023-abdominal-trauma-detection'\n",
    "RESOL = 256\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.00001\n",
    "N_EPOCHS = 30\n",
    "train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "train_meta_df = pd.read_csv(f'{BASE_PATH}/train_meta.csv')\n",
    "train_df = train_df.sort_values(by=['patient_id'])\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#DEVICE = 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AbdominalCTDataset(Dataset):\n",
    "    def __init__(self, meta_df):\n",
    "        self.meta_df = meta_df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta_df.iloc[idx]\n",
    "        label = row[['bowel_healthy','bowel_injury',\n",
    "                    'extravasation_healthy','extravasation_injury',\n",
    "                    'kidney_healthy','kidney_low','kidney_high',\n",
    "                    'liver_healthy','liver_low','liver_high',\n",
    "                    'spleen_healthy','spleen_low','spleen_high',\n",
    "                    'any_injury']]\n",
    "        data_3d = cv2.imread(row['path'], cv2.IMREAD_GRAYSCALE)\n",
    "        data_3d = cv2.equalizeHist(data_3d)\n",
    "        data_3d = data_3d.reshape(1, RESOL, RESOL, RESOL).astype(float)  # channel, 3D\n",
    "        #avg std\n",
    "        data_3d -=47.5739\n",
    "        data_3d /=34.6175\n",
    "        data_3d = torch.from_numpy(data_3d.astype(np.float32))\n",
    "        label = label.to_numpy().astype(np.float32)\n",
    "                \n",
    "        any_injury = label[-1]\n",
    "        nu_any_injury = np.zeros(2)\n",
    "        nu_any_injury[int(any_injury)]= 1\n",
    "        \n",
    "        label = np.hstack([label[:-1], nu_any_injury])\n",
    "        label = torch.from_numpy(label)\n",
    "        return data_3d, label        \n",
    "\n",
    "train_dataset = AbdominalCTDataset(train_meta_df)\n",
    "data_3d, label = train_dataset[0]\n",
    "print(label)\n",
    "\n",
    "del train_dataset, data_3d, label\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#normalizatino parameter\\ntrain_dataset = AbdominalCTDataset(train_meta_df)\\ndata_3d, label = train_dataset[0]\\n\\navgs = np.zeros(len(train_dataset))\\nstds = np.zeros(len(train_dataset))\\nfor i in tqdm(range(0, len(train_dataset))):\\n    data_3d, label = train_dataset[i]\\n    data_3d = data_3d.numpy()\\n    avgs[i] = np.average(data_3d)\\n    stds[i] = np.std(data_3d)\\nprint(np.average(avgs))\\nprint(np.average(stds))    \\n\\ndel train_dataset, data_3d, label, avgs, stds\\ngc.collect()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#normalizatino parameter\n",
    "train_dataset = AbdominalCTDataset(train_meta_df)\n",
    "data_3d, label = train_dataset[0]\n",
    "\n",
    "avgs = np.zeros(len(train_dataset))\n",
    "stds = np.zeros(len(train_dataset))\n",
    "for i in tqdm(range(0, len(train_dataset))):\n",
    "    data_3d, label = train_dataset[i]\n",
    "    data_3d = data_3d.numpy()\n",
    "    avgs[i] = np.average(data_3d)\n",
    "    stds[i] = np.std(data_3d)\n",
    "print(np.average(avgs))\n",
    "print(np.average(stds))    \n",
    "\n",
    "del train_dataset, data_3d, label, avgs, stds\n",
    "gc.collect()\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalClassifier(nn.Module):\n",
    "    def __init__(self, model_depth, device = DEVICE):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.resnet3d = generate_model(model_depth = model_depth, n_input_channels = 1)\n",
    "        self.flatten  = nn.Flatten()\n",
    "        self.dropout  = nn.Dropout(p=0.5)\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "        self.sigmoid  = nn.Sigmoid()\n",
    "        size_res_out  = 56832\n",
    "        self.fc_bowel = nn.Linear(size_res_out, 2)\n",
    "        self.fc_extrav= nn.Linear(size_res_out, 2)\n",
    "        self.fc_kidney= nn.Linear(size_res_out, 3)\n",
    "        self.fc_liver = nn.Linear(size_res_out, 3)\n",
    "        self.fc_spleen= nn.Linear(size_res_out, 3)\n",
    "        self.fc_any   = nn.Linear(size_res_out+13, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet3d(x)\n",
    "        for i in range(0, 4):\n",
    "            x[i] = self.flatten(x[i])\n",
    "        x = torch.cat(x, axis = 1)\n",
    "        x     = self.dropout(x)\n",
    "        bowel = self.fc_bowel(x)\n",
    "        extrav= self.fc_extrav(x)\n",
    "        kidney= self.fc_kidney(x)\n",
    "        liver = self.fc_liver(x)\n",
    "        spleen= self.fc_spleen(x)\n",
    "\n",
    "        label_except_any = torch.cat([x, bowel, extrav, kidney, liver, spleen], dim=1)\n",
    "        any_in = self.fc_any(label_except_any)\n",
    "\n",
    "        labels = torch.cat([bowel, extrav, kidney, liver, spleen, any_in], dim = 1)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34012521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AbdominalClassifier(18)\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(get_n_params(model))\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']!=0])\n",
    "valid_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']==0])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, shuffle = True, batch_size = BATCH_SIZE, pin_memory = True, \n",
    "                          num_workers = 8, drop_last = False)\n",
    "\n",
    "valid_loader = DataLoader(dataset = valid_dataset, shuffle = False, batch_size = BATCH_SIZE, pin_memory = True, \n",
    "                          num_workers = 8, drop_last = False)                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AbdominalClassifier(18)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = LR)\n",
    "ttl_iters = N_EPOCHS * len(train_loader)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
    "\n",
    "\n",
    "weights = np.ones(2)\n",
    "weights[1] = 2\n",
    "crit_bowel  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "weights[1] = 6\n",
    "crit_extrav = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_any_in = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "\n",
    "weights = np.ones((3))\n",
    "weights[1] = 2\n",
    "weights[2] = 4\n",
    "crit_kidney = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_liver  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_spleen = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93e71c5db034aaeadcdc812def813a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/473 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseonglee/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/nn/modules/conv.py:608: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv3d(\n",
      "/home/junseonglee/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 15.70 GiB total capacity; 7.34 GiB already allocated; 1.57 GiB free; 12.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m crit_spleen(X_out[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m], y[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m])\n\u001b[1;32m     21\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m crit_any_in(X_out[:,\u001b[39m13\u001b[39m:\u001b[39m15\u001b[39m], y[:,\u001b[39m13\u001b[39m:\u001b[39m15\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m scaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     24\u001b[0m scaler\u001b[39m.\u001b[39mstep(optimizer)\n\u001b[1;32m     25\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.06/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 15.70 GiB total capacity; 7.34 GiB already allocated; 1.57 GiB free; 12.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "val_losses = np.ones(N_EPOCHS)*100\n",
    "for epoch in range(0, N_EPOCHS):\n",
    "    train_meters = {'loss': AverageMeter()}\n",
    "    val_meters   = {'loss': AverageMeter()}\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, leave=False)\n",
    "    for X, y in pbar:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            X_out  = model(X)\n",
    "\n",
    "            loss  = crit_bowel(X_out[:,:2], y[:,:2])\n",
    "            loss += crit_extrav(X_out[:,2:4], y[:,2:4])\n",
    "            loss += crit_kidney(X_out[:,4:7], y[:,4:7])\n",
    "            loss += crit_liver(X_out[:,7:10], y[:,7:10])\n",
    "            loss += crit_spleen(X_out[:,10:13], y[:,10:13])\n",
    "            loss += crit_any_in(X_out[:,13:15], y[:,13:15])\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scheduler.step()\n",
    "            scaler.update()          \n",
    "\n",
    "        trn_loss = loss.item()      \n",
    "        train_meters['loss'].update(trn_loss, n=X.size(0))     \n",
    "        pbar.set_description(f'Train loss: {trn_loss}')\n",
    "        #print(trn_loss)     \n",
    "    print('Epoch {:d} / trn/loss={:.4f}'.format(epoch+1, train_meters['loss'].avg))    \n",
    "\n",
    "    model.eval()\n",
    "    for X, y in tqdm(valid_loader, leave=False):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            with torch.no_grad(): \n",
    "                X_out = model(X)\n",
    "                #X_out = torch.log(X_out)\n",
    "                loss  = crit_bowel(X_out[:,:2], y[:,:2])\n",
    "                loss += crit_extrav(X_out[:,2:4], y[:,2:4])\n",
    "                loss += crit_kidney(X_out[:,4:7], y[:,4:7])\n",
    "                loss += crit_liver(X_out[:,7:10], y[:,7:10])\n",
    "                loss += crit_spleen(X_out[:,10:13], y[:,10:13])\n",
    "                #how about connecting it to other injuries?\n",
    "                loss += crit_any_in(X_out[:,13:15], y[:,13:15])\n",
    "                val_loss = loss.item()\n",
    "        val_meters['loss'].update(val_loss, n=X.size(0))\n",
    "    print('Epoch {:d} / val/loss={:.4f}'.format(epoch+1, val_meters['loss'].avg))\n",
    "    #Save the best model\n",
    "    if(val_meters['loss'].avg < np.min(val_losses)):\n",
    "        try:\n",
    "            os.makedirs(f'{BASE_PATH}/weights')\n",
    "        except:\n",
    "            a = 1\n",
    "        best_loss = val_meters['loss'].avg\n",
    "        print(f'Best val_loss {best_loss} at epoch {epoch+1}!')\n",
    "        torch.save(model, f'{BASE_PATH}/weights/best.pt')    \n",
    "    \n",
    "    val_losses[epoch] = val_meters['loss'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
