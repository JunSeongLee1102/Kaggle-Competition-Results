{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This is the code for the preprocessing of the 3d images with mask labels.  \n",
    "So only apply preprocessing for the images that have labels (206 samples among about 3700 total samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from glob import glob\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pydicom\n",
    "import dicomsdl\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import gzip\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from multiprocessing import Pool\n",
    "import nibabel as nib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH  = '/home/junseonglee/Desktop/01_codes/inputs/rsna-2023-abdominal-trauma-detection'\n",
    "TRAIN_PATH = f'{BASE_PATH}/train_images'\n",
    "DATA_PATH = f'{BASE_PATH}/3d_preprocessed'\n",
    "\n",
    "if not os.path.isdir(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)\n",
    "\n",
    "RESOL = 128\n",
    "N_FOLDS  = 5\n",
    "N_PREPROCESS_CHUNKS = 12\n",
    "\n",
    "train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "train_df = train_df.sort_values(by=['patient_id'])\n",
    "\n",
    "# Mask related parameters\n",
    "# Order 1: Bowel, 2: left kidney, 3: right kidney, 4: liver, 5: spleen\n",
    "MASK_ORDER = [5, 3, 4, 1, 2]\n",
    "\n",
    "BASE_PATH = '/home/junseonglee/Desktop/01_codes/inputs/rsna-2023-abdominal-trauma-detection'\n",
    "MASK_SAVE_PATH = f'{BASE_PATH}/mask_preprocessed'\n",
    "\n",
    "if not os.path.isdir(MASK_SAVE_PATH):\n",
    "    os.mkdir(MASK_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path definition\n",
    "## For the 3D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "train_meta = pd.read_csv(f'{BASE_PATH}/train_series_meta.csv')\n",
    "train_df = train_df.sort_values(by=['patient_id'])\n",
    "train_df\n",
    "\n",
    "TRAIN_PATH = BASE_PATH + \"/train_images/\"\n",
    "n_chunk = 8\n",
    "patients = os.listdir(TRAIN_PATH)\n",
    "n_patients = len(patients)\n",
    "rng_patients = np.linspace(0, n_patients+1, n_chunk+1, dtype = int)\n",
    "patients_cts = glob(f'{TRAIN_PATH}/*/*')\n",
    "n_cts = len(patients_cts)\n",
    "patients_cts_arr = np.zeros((n_cts, 2), int)\n",
    "data_paths=[]\n",
    "for i in range(0, n_cts):\n",
    "    patient, ct = patients_cts[i].split('/')[-2:]\n",
    "    patients_cts_arr[i] = patient, ct\n",
    "    data_paths.append(f'{BASE_PATH}/3d_preprocessed/{patients_cts_arr[i,0]}_{patients_cts_arr[i,1]}.pkl')\n",
    "TRAIN_IMG_PATH = BASE_PATH + '/processed' \n",
    "\n",
    "#Generate tables for training\n",
    "train_meta_df = pd.DataFrame(patients_cts_arr, columns = ['patient_id', 'series'])\n",
    "\n",
    "#5-fold splitting\n",
    "train_df['fold'] = 0\n",
    "labels = train_df[['bowel_healthy','bowel_injury',\n",
    "                    'extravasation_healthy','extravasation_injury',\n",
    "                    'kidney_healthy','kidney_low','kidney_high',\n",
    "                    'liver_healthy','liver_low','liver_high',\n",
    "                    'spleen_healthy','spleen_low','spleen_high',\n",
    "                    'any_injury']].to_numpy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=0)\n",
    "counter = 0\n",
    "for train_index, test_index in mskf.split(np.ones(len(train_df)), labels):\n",
    "    for i in range(0, len(test_index)):\n",
    "        train_df['fold'][test_index[i]] = counter\n",
    "    counter+=1\n",
    "\n",
    "train_meta_df = train_meta_df.join(train_df.set_index('patient_id'), on='patient_id')\n",
    "train_meta_df['path']=data_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation mask part\n",
    "img_list = glob(f'{BASE_PATH}/train_images/*/*')\n",
    "\n",
    "#To know which mask belongs to which patients\n",
    "series_to_patient_dict = {}\n",
    "for i in range(0, len(img_list)):\n",
    "    tmp = img_list[i].split('/')\n",
    "    series_to_patient_dict[int(tmp[-1])] = int(tmp[-2])\n",
    "\n",
    "seg_path_list = glob(f'{BASE_PATH}/segmentations/*')\n",
    "seg_info_arr = np.zeros((len(seg_path_list), 2), int)\n",
    "for i in range(0, len(seg_path_list)):\n",
    "    series  = int(seg_path_list[i].split('/')[-1][:-4])\n",
    "    patient = series_to_patient_dict[series]\n",
    "    seg_info_arr[i,0] = patient\n",
    "    seg_info_arr[i,1] = series\n",
    "\n",
    "seg_info_df = pd.DataFrame(seg_info_arr, columns = ['patient_id', 'series'])\n",
    "seg_info_df['mask_path'] = ''\n",
    "mask_paths = []\n",
    "for i in range(0, len(seg_info_df)):\n",
    "    row = seg_info_df.iloc[i]\n",
    "    patient_id = row['patient_id']\n",
    "    series = row['series']\n",
    "    mask_paths.append(f'{MASK_SAVE_PATH}/{patient_id}_{series}.pkl')\n",
    "seg_info_df['mask_path'] = mask_paths\n",
    "\n",
    "#train_meta_df = pd.read_csv(f'{BASE_PATH}/train_meta.csv')\n",
    "seg_info_df['img_path'] = ''\n",
    "img_paths = []\n",
    "for i in tqdm(range(0, len(seg_info_df))):\n",
    "    row = seg_info_df.iloc[i]\n",
    "    patient_id = row['patient_id']\n",
    "    series     = row['series']\n",
    "    train_img_path = train_meta_df.loc[(train_meta_df['patient_id']==patient_id)&(train_meta_df['series']==series), 'path']\n",
    "    img_paths.append(train_img_path.iloc[0])\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "seg_info_df['img_path'] = img_paths\n",
    "seg_info_df.to_csv(f'{BASE_PATH}/seg_info.csv', index = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_info_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess input dcm slices to 3d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(name, data):\n",
    "    with gzip.open(name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def decompress(name):\n",
    "    with gzip.open(name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each slice and stack them to make 3d data\n",
    "def process_3d(save_path, data_path = TRAIN_PATH):\n",
    "    tmp = save_path.split('/')[-1][:-4]\n",
    "    tmp = tmp.split('_')\n",
    "    patient, study = int(tmp[0]), int(tmp[1])\n",
    "    imgs = {}    \n",
    "    \n",
    "    # To get dicom to know whether inversion of the pixel values is needed\n",
    "    for f in sorted(glob(data_path + f'/{patient}/{study}/*.dcm')):      \n",
    "        try:\n",
    "            dicom = pydicom.dcmread(f)        \n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "                    \n",
    "    # To load only needed slices\n",
    "    file_list = sorted(glob(data_path + f'/{patient}/{study}/*.dcm'))\n",
    "    file_ind_list = np.zeros(len(file_list), int)\n",
    "    for i in range(0, len(file_list)):\n",
    "        file_ind_list[i] = int(file_list[i].split('/')[-1][:-4])    \n",
    "    file_order_list = np.argsort(file_ind_list)\n",
    "    sample_z = np.linspace(0, len(file_list)-1, RESOL, dtype=int)\n",
    "    \n",
    "    for i in range(0, len(file_list)):\n",
    "        if not np.isin([i], sample_z)[0]:\n",
    "            continue        \n",
    "        f= file_list[file_order_list[i]]         \n",
    "        img = dicomsdl.open(f).pixelData(storedvalue=True).astype(float)\n",
    "        pos_z = -int((f.split('/')[-1])[:-4])\n",
    "        imgs[pos_z] = img\n",
    "\n",
    "    #Sort slices and stack\n",
    "    imgs_3d = []\n",
    "    for i, k in enumerate(sorted(imgs.keys())):\n",
    "        if i in sample_z:\n",
    "            img = imgs[k]\n",
    "            imgs_3d.append(cv2.resize(img, (RESOL, RESOL))[None])    \n",
    "    imgs_3d = np.vstack(imgs_3d)    \n",
    "    \n",
    "    resized_imgs_3d = np.zeros((RESOL, RESOL, RESOL))\n",
    "    for i in range(0, len(imgs_3d[0,0])):\n",
    "        resized_imgs_3d[:,:,i] = cv2.resize(imgs_3d[:,:,i], (RESOL, RESOL))\n",
    "    imgs_3d  = resized_imgs_3d           \n",
    "\n",
    "    #Image normalized & inversion + Standardization\n",
    "    imgs_3d = ((imgs_3d - imgs_3d.min()) / (imgs_3d.max() - imgs_3d.min()))\n",
    "    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        imgs_3d = 1.0 - imgs_3d    \n",
    "            \n",
    "    std = np.std(imgs_3d)\n",
    "    avg = np.average(imgs_3d)\n",
    "    imgs_3d = (imgs_3d-avg)/std\n",
    "    imgs_3d = imgs_3d.astype(np.float32)\n",
    "\n",
    "    #Save the image\n",
    "    compress(save_path, imgs_3d)                      \n",
    "\n",
    "    del imgs, img, resized_imgs_3d\n",
    "    gc.collect()\n",
    "\n",
    "    return imgs_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "rng_samples = np.linspace(0, len(train_meta_df), N_PREPROCESS_CHUNKS+1, dtype = int)\n",
    "def process_3d_wrapper(process_ind, rng_samples = rng_samples, df = train_meta_df):\n",
    "    for i in tqdm(range(rng_samples[process_ind], rng_samples[process_ind+1])):\n",
    "        process_3d(df.iloc[i]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Parallel(n_jobs = N_PREPROCESS_CHUNKS)(delayed(process_3d_wrapper)(i) for i in range(N_PREPROCESS_CHUNKS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess masks to 3d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3D_segmentations(filepath, downsample_rate=2):\n",
    "    img = nib.load(filepath).get_fdata()\n",
    "    img = np.transpose(img, [1, 0, 2])\n",
    "    img = np.rot90(img, 1, (1,2))\n",
    "    img = img[::-1,:,:]\n",
    "    img = np.transpose(img, [1, 0, 2])\n",
    "    img = np.flip(img, 0)\n",
    "\n",
    "    if(len(img)>256):\n",
    "        img = img[::downsample_rate, ::downsample_rate, ::downsample_rate]\n",
    "    else:\n",
    "        img = img[:,::downsample_rate, ::downsample_rate]\n",
    "    return img\n",
    "\n",
    "def img_to_masks(img, mask_order  = MASK_ORDER):\n",
    "    imgs_stack = []    \n",
    "    for i in range(0, len(mask_order)):\n",
    "        one_mask = (img==mask_order[i]).astype(np.uint8)\n",
    "        imgs_stack.append(one_mask[None])\n",
    "\n",
    "    imgs_stack = np.vstack(imgs_stack)    \n",
    "    return imgs_stack\n",
    "\n",
    "def resize_3d(img, resol = RESOL):\n",
    "    imgs_stack = []\n",
    "    for i in range(0, len(img)):\n",
    "        imgs_stack.append(cv2.resize(img[i], (resol, resol))[None])\n",
    "    imgs_stack = np.vstack(imgs_stack)\n",
    "\n",
    "    resized_img = np.zeros((resol, resol, resol), np.uint8)\n",
    "    for i in range(0, len(imgs_stack[0,0])):\n",
    "        resized_img[:,:,i] = cv2.resize(imgs_stack[:,:,i], (resol, resol))\n",
    "    del imgs_stack\n",
    "    gc.collect()\n",
    "    return resized_img\n",
    "\n",
    "def process_mask(path):\n",
    "    series = path.split('/')[-1].split('_')[-1][:-4]\n",
    "    origin_mask_path = f'{BASE_PATH}/segmentations/{series}.nii'\n",
    "    img_3d = create_3D_segmentations(origin_mask_path)\n",
    "    mask_3d = img_to_masks(img_3d)    \n",
    "    resized_mask_3d = np.zeros((len(mask_3d), RESOL, RESOL, RESOL), np.uint8)\n",
    "    for i in range(0, len(MASK_ORDER)):\n",
    "        resized_mask_3d[i] = resize_3d(mask_3d[i])\n",
    "    compress(path, resized_mask_3d)\n",
    "    del img_3d, mask_3d, resized_mask_3d\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "rng_samples = np.linspace(0, len(seg_info_df), N_PREPROCESS_CHUNKS+1, dtype = int)\n",
    "def process_3d_wrapper(process_ind, rng_samples = rng_samples, seg_info_df = seg_info_df):\n",
    "    for i in tqdm(range(rng_samples[process_ind], rng_samples[process_ind+1])):\n",
    "        process_mask(seg_info_df.iloc[i]['mask_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Parallel(n_jobs = N_PREPROCESS_CHUNKS)(delayed(process_3d_wrapper)(i) for i in range(N_PREPROCESS_CHUNKS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_info_df = pd.read_csv(f'{BASE_PATH}/seg_info.csv')\n",
    "\n",
    "for i in range(0, len(seg_info_df)):\n",
    "    if (i !=15):\n",
    "        continue\n",
    "    row = seg_info_df.iloc[i]\n",
    "    img_3d = decompress(row['img_path'])\n",
    "    mask   = decompress(row['mask_path'])\n",
    "    f, axs = plt.subplots(1, 6, figsize=(18, 3))\n",
    "    plt.title(f'Ind {i}')\n",
    "    axs[0].imshow(img_3d[:,64,:])\n",
    "    for j in range(0, 5):\n",
    "        axs[j+1].imshow(mask[j,:,64,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
