{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseonglee/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjunseonglee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/junseonglee/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "sys.path.append('./lib_models')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.metrics\n",
    "import warnings\n",
    "import pydicom\n",
    "import dicomsdl\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import gzip\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from multiprocessing import Pool\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch import nn\n",
    "from torchvision.io import read_image\n",
    "import segmentation_models_pytorch as smp\n",
    "import timm\n",
    "from timm.utils import AverageMeter\n",
    "from timm.models import resnet\n",
    "import timm_new\n",
    "\n",
    "from monai.transforms import Resize\n",
    "import  monai.transforms as transforms\n",
    "\n",
    "from timm.models.layers.conv2d_same import Conv2dSame\n",
    "from conv3d_same import Conv3dSame\n",
    "\n",
    "\n",
    "import wandb\n",
    "sys.path.append('./lib_models')\n",
    "\n",
    "wandb.login(key = '585f58f321685308f7933861d9dde7488de0970b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = 'timm/resnet10t.c3_in1k'\n",
    "\n",
    "IS_WANDB = True\n",
    "PROJECT_NAME = 'RSNA_ABTD'\n",
    "GROUP_NAME= 'preprocessing_test'\n",
    "RUN_NAME=   f'{backbone}_2nd'\n",
    "\n",
    "if not IS_WANDB:\n",
    "    PROJECT_NAME = 'Dummy_Project'\n",
    "\n",
    "BASE_PATH  = '/home/junseonglee/Desktop/01_codes/inputs/rsna-2023-abdominal-trauma-detection'\n",
    "TRAIN_PATH = f'{BASE_PATH}/train_images'\n",
    "DATA_PATH = f'{BASE_PATH}/3d_preprocessed'\n",
    "\n",
    "seg_inference_dir = f'{BASE_PATH}/seg_infer_results'\n",
    "cropped_img_dir   = f'{BASE_PATH}/3d_preprocessed_crop_ratio'\n",
    "\n",
    "if not os.path.isdir(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)\n",
    "\n",
    "RESOL = 128\n",
    "UP_RESOL = 128\n",
    "N_CHANNELS = 6\n",
    "BATCH_SIZE = 8\n",
    "ACCUM_STEPS = 3\n",
    "N_WORKERS  = 8\n",
    "LR = 0.001\n",
    "N_EPOCHS = 200\n",
    "EARLY_STOP_COUNT = 30\n",
    "N_FOLDS  = 5\n",
    "N_PREPROCESS_CHUNKS = 12\n",
    "PCT_START = 0.3\n",
    "n_blocks = 4\n",
    "drop_rate = 0.2\n",
    "drop_path_rate = 0.2\n",
    "p_mixup = 0.0\n",
    "\n",
    "\n",
    "\n",
    "DROP_REGION= {'HOLES': [3, 20],\n",
    "                'SIZE': [5, 20],\n",
    "                'PROB': 0.5,\n",
    "                'FILL': (-3, 3)}\n",
    "\n",
    "wandb_config = {\n",
    "    'RESOL': RESOL,\n",
    "    'BACKBONE': backbone,\n",
    "    'N_CHANNELS': N_CHANNELS,\n",
    "    'N_EPOCHS': N_EPOCHS,\n",
    "    'N_FOLDS': N_FOLDS,\n",
    "    'EARLY_STOP_COUNT': EARLY_STOP_COUNT,\n",
    "    'BATCH_SIZE': BATCH_SIZE,    \n",
    "    'LR': LR,\n",
    "    'N_EPOCHS': N_EPOCHS,\n",
    "    'DROP_RATE': drop_rate,\n",
    "    'DROP_PATH_RATE': drop_path_rate,\n",
    "    'MIXUP_RATE': p_mixup,\n",
    "    'DROP_REGION': DROP_REGION,\n",
    "    'PCT_START': PCT_START\n",
    "}\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([929, 947, 948, 951, 936]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask related parameters\n",
    "# Order 0: Bowel, 1: left kidney, 2: right kidney, 3: liver, 4: spleen\n",
    "\n",
    "chan_keys = ['bowel', 'left_kidney', 'right_kidney', 'liver', 'spleen', 'total']\n",
    "chan_dict = {}\n",
    "for i in range(0, 6):\n",
    "    chan_dict[i] = chan_keys[i]\n",
    "\n",
    "train_meta_df = pd.read_csv(f'{BASE_PATH}/train_meta.csv')\n",
    "np.unique(train_meta_df['fold'].to_numpy(), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(name, data):\n",
    "    with gzip.open(name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def decompress(name):\n",
    "    with gzip.open(name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def compress_fast(name, data):\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def decompress_fast(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_3d(module):\n",
    "\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    elif isinstance(module, Conv2dSame):\n",
    "        module_output = Conv3dSame(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timm3DModel(nn.Module):\n",
    "    def __init__(self, backbone, n_channels, n_labels, segtype='unet', pretrained=False):\n",
    "        super(Timm3DModel, self).__init__()\n",
    "        self.n_labels = n_labels\n",
    "        self.encoder = timm_new.create_model(\n",
    "            backbone,\n",
    "            in_chans=n_channels,\n",
    "            features_only=True,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, n_channels, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(5, 4, 2)\n",
    "        \n",
    "        [_.shape[1] for _ in g]\n",
    "        self.convs1x1 = nn.ModuleList()    \n",
    "        self.batchnorms = nn.ModuleList()    \n",
    "        self.batchnorms13 = nn.ModuleList()\n",
    "        for i in range(0, len(g)):\n",
    "            self.convs1x1.append(nn.Conv2d(g[i].shape[1], self.n_labels, 1))\n",
    "        del g\n",
    "        gc.collect()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        global_features = self.encoder(x)[:n_blocks]        \n",
    "        for i in range(0, len(global_features)):\n",
    "            global_features[i] = self.convs1x1[i](global_features[i])\n",
    "        return global_features\n",
    "    \n",
    "    \n",
    "class Timm3DModelClassifier(nn.Module):\n",
    "    def __init__(self, backbone, n_channels, n_labels, segtype='unet', pretrained=False):\n",
    "        super(Timm3DModelClassifier, self).__init__()\n",
    "        self.model_3d = Timm3DModel(backbone, n_channels, n_labels, segtype, pretrained)\n",
    "        self.model_3d = convert_3d(self.model_3d)\n",
    "        self.n_channels = n_channels\n",
    "        self.n_labels = n_labels    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.model_3d(x)\n",
    "        pooled_features = []\n",
    "        for i in range(0, len(x)):\n",
    "            pooled_features.append(torch.reshape(torch.mean(x[i], dim = (2, 3, 4)), (batch_size, self.n_labels, 1)))\n",
    "        pooled_features = torch.cat(pooled_features, dim=2)     \n",
    "        labels = torch.mean(pooled_features, dim = 2)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalClassifier(nn.Module):\n",
    "    def __init__(self, device = DEVICE):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.upsample = torch.nn.Upsample(size = [UP_RESOL, UP_RESOL, UP_RESOL])\n",
    "        \n",
    "        self.model3d_bowel        = Timm3DModelClassifier(backbone, 1, 2)      \n",
    "        self.model3d_extrav       = Timm3DModelClassifier(backbone, 1, 2)\n",
    "        self.model3d_kidney_left  = Timm3DModelClassifier(backbone, 1, 3)\n",
    "        self.model3d_kidney_right = Timm3DModelClassifier(backbone, 1, 3)\n",
    "        self.model3d_liver        = Timm3DModelClassifier(backbone, 1, 3)\n",
    "        self.model3d_spleen       = Timm3DModelClassifier(backbone, 1, 3)\n",
    "        \n",
    "        self.flatten  = nn.Flatten()\n",
    "        self.dropout  = nn.Dropout(p=0.5)\n",
    "        self.softmax  = nn.Softmax(dim=1)        \n",
    "        self.maxpool  = nn.MaxPool1d(5, 1)\n",
    "        \n",
    "    def forward(self, x_bowel, x_kidney_left, x_kidney_right, x_liver, x_spleen, x_total):\n",
    "        bowel_label        = self.model3d_bowel(x_bowel)\n",
    "        extrav_label       = self.model3d_extrav(x_total)\n",
    "        kidney_label_left  = self.model3d_kidney_left(x_kidney_left)\n",
    "        kidney_label_right = self.model3d_kidney_right(x_kidney_right)\n",
    "        kidney_label       = (kidney_label_left + kidney_label_right)/2\n",
    "        liver_label        = self.model3d_liver(x_liver)\n",
    "        spleen_label       = self.model3d_spleen(x_spleen)\n",
    "        \n",
    "        \n",
    "        labels = torch.cat([bowel_label, extrav_label, kidney_label, liver_label, spleen_label], dim = 1)\n",
    "        \n",
    "        bowel_soft = self.softmax(bowel_label)\n",
    "        extrav_soft = self.softmax(extrav_label)\n",
    "        kidney_soft = self.softmax(kidney_label)\n",
    "        liver_soft = self.softmax(liver_label)\n",
    "        spleen_soft = self.softmax(spleen_label)\n",
    "\n",
    "        any_in = torch.cat([1-bowel_soft[:,0:1], 1-extrav_soft[:,0:1], \n",
    "                            1-kidney_soft[:,0:1], 1-liver_soft[:,0:1], 1-spleen_soft[:,0:1]], dim = 1) \n",
    "        any_in = self.maxpool(any_in)\n",
    "        any_not_in = 1-any_in\n",
    "        any_in = torch.cat([any_not_in, any_in], dim = 1)\n",
    "\n",
    "        return labels, any_in\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86478624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AbdominalClassifier()\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(get_n_params(model))\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones(2)\n",
    "weights[1] = 2\n",
    "crit_bowel  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "weights[1] = 6\n",
    "crit_extrav = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_any = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "\n",
    "weights = np.ones((3))\n",
    "weights[1] = 2\n",
    "weights[2] = 4\n",
    "crit_kidney = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_liver  = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))\n",
    "crit_spleen = nn.CrossEntropyLoss(weight = torch.from_numpy(weights).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_one(tensor):\n",
    "    norm = torch.sum(tensor, 1)\n",
    "    for i in range(0, tensor.shape[1]):\n",
    "        tensor[:,i]/=norm\n",
    "    return tensor\n",
    "\n",
    "def apply_softmax_to_labels(X_out):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    X_out[:,:2]    = normalize_to_one(softmax(X_out[:,:2]))\n",
    "    X_out[:,2:4]   = normalize_to_one(softmax(X_out[:,2:4]))\n",
    "    X_out[:,4:7]   = normalize_to_one(softmax(X_out[:,4:7]))\n",
    "    X_out[:,7:10]  = normalize_to_one(softmax(X_out[:,7:10]))\n",
    "    X_out[:,10:13] = normalize_to_one(softmax(X_out[:,10:13]))\n",
    "\n",
    "    return X_out\n",
    "\n",
    "def calculate_score(X_outs, ys, step = 'train'):\n",
    "    X_outs = X_outs.astype(np.float64)\n",
    "    ys     = ys.astype(np.float64)\n",
    "\n",
    "    isnan_x = np.isnan(X_outs).astype(int)\n",
    "    isnan_y = np.isnan(ys).astype(int)\n",
    "    \n",
    "    if(np.max(isnan_x)>0):\n",
    "        print('xnan')\n",
    "    if(np.max(isnan_y)>0):\n",
    "        print('ynan')\n",
    "\n",
    "    bowel_weights  =  ys[:,0] + 2*ys[:,1]\n",
    "    extrav_weights = ys[:,2] + 6*ys[:,3]\n",
    "    kidney_weights = ys[:,4] + 2*ys[:,5] + 4*ys[:,6]\n",
    "    liver_weights  = ys[:,7] + 2*ys[:,8] + 4*ys[:,9]\n",
    "    spleen_weights = ys[:,10] + 2*ys[:,11] + 4*ys[:,12]\n",
    "    any_in_weights = ys[:,13] + 6*ys[:,14]\n",
    "\n",
    "    bowel_loss  = sklearn.metrics.log_loss(ys[:,:2], X_outs[:,:2], sample_weight = bowel_weights.astype(np.float64))\n",
    "    extrav_loss = sklearn.metrics.log_loss(ys[:,2:4], X_outs[:,2:4], sample_weight = extrav_weights.astype(np.float64))\n",
    "    kidney_loss = sklearn.metrics.log_loss(ys[:,4:7], X_outs[:,4:7], sample_weight = kidney_weights.astype(np.float64))\n",
    "    liver_loss  = sklearn.metrics.log_loss(ys[:,7:10], X_outs[:,7:10], sample_weight = liver_weights.astype(np.float64))\n",
    "    spleen_loss = sklearn.metrics.log_loss(ys[:,10:13], X_outs[:,10:13], sample_weight = spleen_weights.astype(np.float64))\n",
    "    any_in_loss = sklearn.metrics.log_loss(ys[:,13:15], X_outs[:,13:15], sample_weight =  any_in_weights.astype(np.float64))\n",
    "    \n",
    "    avg_loss = (bowel_loss + extrav_loss + kidney_loss + liver_loss + spleen_loss + any_in_loss)/6\n",
    "\n",
    "    losses= {f'{step}_bowel_metric': bowel_loss, f'{step}_extrav_metric': extrav_loss, f'{step}_kidney_metric': kidney_loss,\n",
    "             f'{step}_liver_metric': liver_loss, f'{step}_spleen_metric': spleen_loss, f'{step}_any_in_metric': any_in_loss,\n",
    "             f'{step}_avg_metric': avg_loss}\n",
    "\n",
    "    wandb.log(losses)\n",
    "    return avg_loss\n",
    "\n",
    "def calculate_loss(X_out, X_any, y):\n",
    "    batch_size = X_out.shape[0]\n",
    "    bowel_loss  = crit_bowel(X_out[:,:2], y[:,:2])\n",
    "    extrav_loss = crit_extrav(X_out[:,2:4], y[:,2:4])\n",
    "    kidney_loss = crit_kidney(X_out[:,4:7], y[:,4:7])\n",
    "    liver_loss  = crit_liver(X_out[:,7:10], y[:,7:10])\n",
    "    spleen_loss = crit_spleen(X_out[:,10:13], y[:,10:13])\n",
    "    any_in_loss = crit_any(X_any,  torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1))\n",
    "    \n",
    "    avg_loss = (bowel_loss + extrav_loss + kidney_loss + liver_loss + spleen_loss + any_in_loss)/6\n",
    "    return bowel_loss, extrav_loss, kidney_loss, liver_loss, spleen_loss, any_in_loss, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(inputs, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(inputs.size(0))\n",
    "    shuffled_input = inputs[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    inputs = inputs * lam + shuffled_input * (1 - lam)\n",
    "    return inputs, truth, shuffled_labels, lam\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandFlipd(keys=chan_keys, prob=0.5, spatial_axis=0),    \n",
    "    transforms.RandFlipd(keys=chan_keys, prob=0.5, spatial_axis=1),\n",
    "    transforms.RandFlipd(keys=chan_keys, prob=0.5, spatial_axis=2),\n",
    "    #transforms.RandAffined(keys=chan_keys, translate_range=[int(x*y) for x, y in zip([RESOL, RESOL, RESOL], [0.3, 0.3, 0.3])], padding_mode='zeros', prob=0.7),\n",
    "    transforms.RandGridDistortiond(keys=chan_keys, prob=0.5, distort_limit=(-0.01, 0.01), mode=\"nearest\"),    \n",
    "])\n",
    "\n",
    "remain_transforms_train = transforms.Compose([\n",
    "    #transforms.RandCoarseDropout(holes = DROP_REGION['HOLES'][0], max_holes = DROP_REGION['HOLES'][1],\n",
    "    #                        spatial_size = DROP_REGION['SIZE'][0]*np.ones(3, int), max_spatial_size =DROP_REGION['SIZE'][1]*np.ones(3, int), \n",
    "    #                        prob = DROP_REGION['PROB'], \n",
    "    #                        fill_value = DROP_REGION['FILL'])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "transforms_common_preprocessing = transforms.Compose([\n",
    "    #transforms.HistogramNormalize(num_bins = 256, min = 0, max = 255)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalCTDataset(Dataset):\n",
    "    def __init__(self, meta_df, is_train = True, transform_set = None, remain_transforms_set = None):\n",
    "        self.meta_df = meta_df\n",
    "        self.is_train = is_train\n",
    "        self.transform_set = transform_set\n",
    "        self.remain_transforms_set = remain_transforms_set\n",
    "        self.data_3ds = []        \n",
    "        for i in tqdm(range(0, len(self.meta_df))):\n",
    "            tmp_data_3ds = {}\n",
    "            base_name = self.meta_df.iloc[i]['cropped_path']            \n",
    "            for j in range(0, 6):\n",
    "                tmp_data_3d = decompress_fast(f'{base_name}_{j}').unsqueeze(0)\n",
    "                #tmp_data_3d = torch.from_numpy(tmp_data_3d)\n",
    "                tmp_data_3ds[chan_dict[j]] = tmp_data_3d            \n",
    "            self.data_3ds.append(tmp_data_3ds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta_df.iloc[idx]\n",
    "        label = row[['bowel_healthy','bowel_injury',\n",
    "                    'extravasation_healthy','extravasation_injury',\n",
    "                    'kidney_healthy','kidney_low','kidney_high',\n",
    "                    'liver_healthy','liver_low','liver_high',\n",
    "                    'spleen_healthy','spleen_low','spleen_high', 'any_injury']]\n",
    "        \n",
    "        data_3d = self.data_3ds[idx].copy()\n",
    "        \n",
    "        if self.is_train:\n",
    "            if self.transform_set is not None:\n",
    "                data_3d = self.transform_set(data_3d)\n",
    "\n",
    "            if self.remain_transforms_set is not None:   \n",
    "                for i in range(0, 6):\n",
    "                    data_3d[chan_dict[i]] = self.remain_transforms_set(data_3d[chan_dict[i]])\n",
    "        \n",
    "        label = label.to_numpy().astype(np.float32)                    \n",
    "        label = torch.from_numpy(label)\n",
    "                    \n",
    "        return data_3d['bowel'], data_3d['left_kidney'], data_3d['right_kidney'], \\\n",
    "                data_3d['liver'], data_3d['spleen'], data_3d['total'], label        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_3d= torch.rand((6, 128, 128, 128))*0.5\n",
    "#data_3d = remain_transforms_train(data_3d)\n",
    "#torch.max(data_3d)\n",
    "#print(data_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(model, train_loader, scaler, scheduler, optimizer, epoch, accum_points, accum_scale):\n",
    "    train_meters = {'loss': AverageMeter()}\n",
    "    model.train()\n",
    "    X_outs=[]\n",
    "    ys=[]\n",
    "    accum_counter = 0\n",
    "    counter = 0\n",
    "    for X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, y in train_loader:\n",
    "        X_bowel, X_lkid, X_rkid = X_bowel.to(DEVICE), X_lkid.to(DEVICE), X_rkid.to(DEVICE)\n",
    "        X_liv, X_spl, X_tot     = X_liv.to(DEVICE), X_spl.to(DEVICE), X_tot.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        current_lr = float(scheduler.get_last_lr()[0])\n",
    "        \n",
    "        batch_size = X_bowel.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=True):  \n",
    "            X_out, X_any  = model(X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot)\n",
    "            bowel_loss, extrav_loss, kidney_loss, liver_loss, spleen_loss, any_in_loss, avg_loss = calculate_loss(X_out, X_any, y)\n",
    "                \n",
    "            step = 'train'\n",
    "            wandb.log({ 'lr': current_lr,\n",
    "                        f'{step}_bowel_loss': bowel_loss.item(),\n",
    "                        f'{step}_extrav_loss': extrav_loss.item(),\n",
    "                        f'{step}_kidney_loss': kidney_loss.item(),\n",
    "                        f'{step}_liver_loss': liver_loss.item(),\n",
    "                        f'{step}_spleen_loss': spleen_loss.item(),\n",
    "                        f'{step}_any_loss': any_in_loss.item(),\n",
    "                        f'{step}_avg_loss': avg_loss.item()\n",
    "                        })\n",
    "            \n",
    "            scaler.scale(avg_loss/accum_scale[accum_counter]).backward()\n",
    "            if(counter==accum_points[accum_counter]):\n",
    "                scaler.step(optimizer)\n",
    "                scheduler.step()\n",
    "                scaler.update()    \n",
    "                accum_counter+=1                \n",
    "        counter+=1                   \n",
    "\n",
    "        #Metric calculation\n",
    "        y_any = torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1)    \n",
    "        X_out = apply_softmax_to_labels(X_out).detach().to('cpu').numpy()\n",
    "        X_any = X_any.detach().to('cpu').numpy()\n",
    "        X_out = np.hstack([X_out, X_any])\n",
    "        X_outs.append(X_out)\n",
    "\n",
    "        y     = y.to('cpu').numpy()[:,:-1]\n",
    "        y_any = y_any.to('cpu').numpy()\n",
    "        y     = np.hstack([y, y_any])\n",
    "        ys.append(y)\n",
    "\n",
    "        trn_loss = avg_loss.item()      \n",
    "        train_meters['loss'].update(trn_loss, n=batch_size)     \n",
    "        #pbar.set_description(f'Train loss: {trn_loss}')   \n",
    "        \n",
    "        \n",
    "    print('Epoch {:d} / trn/loss={:.4f}'.format(epoch+1, train_meters['loss'].avg))    \n",
    "\n",
    "    X_outs = np.vstack(X_outs) \n",
    "    ys     = np.vstack(ys)\n",
    "    metric = calculate_score(X_outs, ys, 'train')                 \n",
    "    print('Epoch {:d} / train/metric={:.4f}'.format(epoch+1, metric))   \n",
    "\n",
    "    del X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, X_outs, y, ys, X_any\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()    \n",
    "    return scheduler, scaler, optimizer\n",
    "\n",
    "\n",
    "def valid_func(model, valid_loader, epoch):\n",
    "    X_outs=[]\n",
    "    ys=[]\n",
    "    model.eval()\n",
    "    for X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, y in valid_loader:\n",
    "        batch_size = y.shape[0]\n",
    "        X_bowel, X_lkid, X_rkid = X_bowel.to(DEVICE), X_lkid.to(DEVICE), X_rkid.to(DEVICE)\n",
    "        X_liv, X_spl, X_tot     = X_liv.to(DEVICE), X_spl.to(DEVICE), X_tot.to(DEVICE)\n",
    "        y = y.to(DEVICE)           \n",
    "        with torch.cuda.amp.autocast(enabled=True):                \n",
    "            with torch.no_grad():                 \n",
    "                X_out, X_any = model(X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot)                                          \n",
    "                y_any = torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1)              \n",
    "                X_out = apply_softmax_to_labels(X_out).to('cpu').numpy()\n",
    "\n",
    "                X_any = X_any.to('cpu').numpy()\n",
    "                X_out = np.hstack([X_out, X_any])\n",
    "                X_outs.append(X_out)\n",
    "\n",
    "                y     = y.to('cpu').numpy()[:,:-1]\n",
    "                y_any = y_any.to('cpu').numpy()\n",
    "                y     = np.hstack([y, y_any])\n",
    "                ys.append(y)\n",
    "\n",
    "    X_outs = np.vstack(X_outs) \n",
    "    ys     = np.vstack(ys)\n",
    "    metric = calculate_score(X_outs, ys, 'valid')                \n",
    "    print('Epoch {:d} / val/metric={:.4f}'.format(epoch+1, metric))           \n",
    "    \n",
    "    del X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, X_outs, y, ys, X_any\n",
    "    gc.collect()        \n",
    "    torch.cuda.empty_cache()   \n",
    "    return metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/junseonglee/Desktop/01_codes/inputs/rsna-2023-abdominal-trauma-detection/wandb/run-20230925_223009-tloo5iex</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/junseonglee/RSNA_ABTD/runs/tloo5iex' target=\"_blank\">timm/resnet10t.c3_in1k_2nd</a></strong> to <a href='https://wandb.ai/junseonglee/RSNA_ABTD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/junseonglee/RSNA_ABTD' target=\"_blank\">https://wandb.ai/junseonglee/RSNA_ABTD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/junseonglee/RSNA_ABTD/runs/tloo5iex' target=\"_blank\">https://wandb.ai/junseonglee/RSNA_ABTD/runs/tloo5iex</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3782/3782 [01:50<00:00, 34.27it/s]\n",
      "100%|██████████| 929/929 [00:35<00:00, 26.08it/s]\n",
      "                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / trn/loss=nan\n",
      "xnan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, N_EPOCHS), leave \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):     \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     scheduler, scaler, optimizer \u001b[39m=\u001b[39m train_func(model, train_loader, scaler, scheduler, optimizer, epoch, accum_points, accum_scale)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     metric                       \u001b[39m=\u001b[39m valid_func(model, valid_loader, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39m#Save the best model    \u001b[39;00m\n",
      "\u001b[1;32m/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m X_outs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(X_outs) \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m ys     \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(ys)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m metric \u001b[39m=\u001b[39m calculate_score(X_outs, ys, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)                 \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m / train/metric=\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, metric))   \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mdel\u001b[39;00m X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, X_outs, y, ys, X_any\n",
      "\u001b[1;32m/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m kidney_loss \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m4\u001b[39m:\u001b[39m7\u001b[39m], X_outs[:,\u001b[39m4\u001b[39m:\u001b[39m7\u001b[39m], sample_weight \u001b[39m=\u001b[39m kidney_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m liver_loss  \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m7\u001b[39m:\u001b[39m10\u001b[39m], X_outs[:,\u001b[39m7\u001b[39m:\u001b[39m10\u001b[39m], sample_weight \u001b[39m=\u001b[39m liver_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m spleen_loss \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m], X_outs[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m], sample_weight \u001b[39m=\u001b[39m spleen_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m any_in_loss \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m13\u001b[39m:\u001b[39m15\u001b[39m], X_outs[:,\u001b[39m13\u001b[39m:\u001b[39m15\u001b[39m], sample_weight \u001b[39m=\u001b[39m  any_in_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m (bowel_loss \u001b[39m+\u001b[39m extrav_loss \u001b[39m+\u001b[39m kidney_loss \u001b[39m+\u001b[39m liver_loss \u001b[39m+\u001b[39m spleen_loss \u001b[39m+\u001b[39m any_in_loss)\u001b[39m/\u001b[39m\u001b[39m6\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2838\u001b[0m, in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   2747\u001b[0m     {\n\u001b[1;32m   2748\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2758\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m ):\n\u001b[1;32m   2760\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Log loss, aka logistic loss or cross-entropy loss.\u001b[39;00m\n\u001b[1;32m   2761\u001b[0m \n\u001b[1;32m   2762\u001b[0m \u001b[39m    This is the loss function used in (multinomial) logistic regression\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2836\u001b[0m \u001b[39m    0.21616...\u001b[39;00m\n\u001b[1;32m   2837\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2838\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   2839\u001b[0m         y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat16]\n\u001b[1;32m   2840\u001b[0m     )\n\u001b[1;32m   2841\u001b[0m     \u001b[39mif\u001b[39;00m eps \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2842\u001b[0m         eps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfinfo(y_pred\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39meps\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "model = AbdominalClassifier()\n",
    "model.to(DEVICE)\n",
    "\n",
    "wandb.init(\n",
    "    config = wandb_config,\n",
    "    project= PROJECT_NAME,\n",
    "    group  = GROUP_NAME,\n",
    "    name   = RUN_NAME,\n",
    "    dir    = BASE_PATH)\n",
    "\n",
    "backbone = backbone.replace('/', '_')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']!=0], is_train = True, transform_set  = transforms_train, \n",
    "                                        remain_transforms_set = remain_transforms_train)\n",
    "    valid_dataset = AbdominalCTDataset(train_meta_df[train_meta_df['fold']==0], is_train = False, transform_set = None,\n",
    "                                        remain_transforms_set = None)        \n",
    "    \n",
    "    train_loader = DataLoader(dataset = train_dataset, shuffle = True, batch_size = BATCH_SIZE, pin_memory = False, \n",
    "                            num_workers = N_WORKERS, drop_last = False)\n",
    "\n",
    "    valid_loader = DataLoader(dataset = valid_dataset, shuffle = False, batch_size = BATCH_SIZE, pin_memory = False, \n",
    "                            num_workers = N_WORKERS, drop_last = False)     \n",
    "    \n",
    "    ttl_iters = N_EPOCHS * len(train_loader)\n",
    "    \n",
    "    #gradient accumulation for stability of the training\n",
    "    accum_len = int(np.ceil(len(train_loader)/ACCUM_STEPS)+0.001)\n",
    "    accum_points = np.zeros(accum_len, int)\n",
    "    accum_scale  = np.zeros(accum_len, int)\n",
    "    \n",
    "    prev_step = -1\n",
    "    for i in range(0, accum_len):\n",
    "        accum_points[i] = min(prev_step+ACCUM_STEPS, len(train_loader)-1)\n",
    "        accum_scale[i]  = accum_points[i] - prev_step\n",
    "        prev_step = accum_points[i]\n",
    "\n",
    "    #Scheduler & optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = LR)\n",
    "    n_batch_iters = int(np.ceil(len(train_loader)/ACCUM_STEPS)+0.001)\n",
    "    #scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR, pct_start= PCT_START,\n",
    "                                                    steps_per_epoch= n_batch_iters, epochs = N_EPOCHS)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "    val_metrics = np.ones(N_EPOCHS)*100\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    for epoch in tqdm(range(0, N_EPOCHS), leave = False):     \n",
    "\n",
    "        scheduler, scaler, optimizer = train_func(model, train_loader, scaler, scheduler, optimizer, epoch, accum_points, accum_scale)\n",
    "        metric                       = valid_func(model, valid_loader, epoch)\n",
    "        \n",
    "        #Save the best model    \n",
    "        if(metric < np.min(val_metrics)):\n",
    "            try:\n",
    "                os.makedirs(f'{BASE_PATH}/weights')\n",
    "            except:\n",
    "                a = 1\n",
    "            best_metric = metric\n",
    "            print(f'Best val_metric {best_metric} at epoch {epoch+1}!')\n",
    "            torch.save(model, f'{BASE_PATH}/weights/{backbone}_lr{LR}_epochs_{N_EPOCHS}_resol{UP_RESOL}_batch{BATCH_SIZE*ACCUM_STEPS}.pt')    \n",
    "            not_improve_counter=0\n",
    "            val_metrics[epoch] = metric\n",
    "            continue                    \n",
    "        val_metrics[epoch] = metric                        \n",
    "        \n",
    "        #Early stopping\n",
    "        not_improve_counter+=1\n",
    "        if(not_improve_counter == EARLY_STOP_COUNT):\n",
    "            print(f'Not improved for {not_improve_counter} epochs, terminate the train')\n",
    "            break\n",
    "wandb.log({'best_total_log_loss': best_metric})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this cell to fininsh the wandb run when you stopped training.\n",
    "\n",
    "import wandb\n",
    "try: \n",
    "    wandb.log({'best_total_log_loss': best_metric})\n",
    "    wandb.finish()\n",
    "    \n",
    "except:\n",
    "    print('Wandb is already finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / trn/loss=nan\n",
      "xnan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb Cell 23\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m X_outs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(X_outs) \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m ys     \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(ys)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m metric \u001b[39m=\u001b[39m calculate_score(X_outs, ys, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)                 \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m / train/metric=\u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, metric))   \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mdel\u001b[39;00m X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, X_outs, y, ys, X_any\n",
      "\u001b[1;32m/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m kidney_loss \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m4\u001b[39m:\u001b[39m7\u001b[39m], X_outs[:,\u001b[39m4\u001b[39m:\u001b[39m7\u001b[39m], sample_weight \u001b[39m=\u001b[39m kidney_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m liver_loss  \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m7\u001b[39m:\u001b[39m10\u001b[39m], X_outs[:,\u001b[39m7\u001b[39m:\u001b[39m10\u001b[39m], sample_weight \u001b[39m=\u001b[39m liver_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m spleen_loss \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m], X_outs[:,\u001b[39m10\u001b[39m:\u001b[39m13\u001b[39m], sample_weight \u001b[39m=\u001b[39m spleen_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m any_in_loss \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mlog_loss(ys[:,\u001b[39m13\u001b[39m:\u001b[39m15\u001b[39m], X_outs[:,\u001b[39m13\u001b[39m:\u001b[39m15\u001b[39m], sample_weight \u001b[39m=\u001b[39m  any_in_weights\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.55.170/home/junseonglee/Desktop/01_codes/Kaggle-Competition-Results/02_RSNA_Abdominal_Trauma/Step2b_train_classification_sep_model_with_cropped_data.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m (bowel_loss \u001b[39m+\u001b[39m extrav_loss \u001b[39m+\u001b[39m kidney_loss \u001b[39m+\u001b[39m liver_loss \u001b[39m+\u001b[39m spleen_loss \u001b[39m+\u001b[39m any_in_loss)\u001b[39m/\u001b[39m\u001b[39m6\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2838\u001b[0m, in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   2747\u001b[0m     {\n\u001b[1;32m   2748\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2758\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m ):\n\u001b[1;32m   2760\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Log loss, aka logistic loss or cross-entropy loss.\u001b[39;00m\n\u001b[1;32m   2761\u001b[0m \n\u001b[1;32m   2762\u001b[0m \u001b[39m    This is the loss function used in (multinomial) logistic regression\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2836\u001b[0m \u001b[39m    0.21616...\u001b[39;00m\n\u001b[1;32m   2837\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2838\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   2839\u001b[0m         y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mfloat16]\n\u001b[1;32m   2840\u001b[0m     )\n\u001b[1;32m   2841\u001b[0m     \u001b[39mif\u001b[39;00m eps \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2842\u001b[0m         eps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfinfo(y_pred\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39meps\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rsna_abtd/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "train_meters = {'loss': AverageMeter()}\n",
    "model.train()\n",
    "X_outs=[]\n",
    "ys=[]\n",
    "accum_counter = 0\n",
    "counter = 0\n",
    "for X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, y in train_loader:\n",
    "    X_bowel, X_lkid, X_rkid = X_bowel.to(DEVICE), X_lkid.to(DEVICE), X_rkid.to(DEVICE)\n",
    "    X_liv, X_spl, X_tot     = X_liv.to(DEVICE), X_spl.to(DEVICE), X_tot.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    current_lr = float(scheduler.get_last_lr()[0])\n",
    "    \n",
    "    batch_size = X_bowel.shape[0]\n",
    "    optimizer.zero_grad()\n",
    "    with torch.cuda.amp.autocast(enabled=True):  \n",
    "        X_out, X_any  = model(X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot)\n",
    "        bowel_loss, extrav_loss, kidney_loss, liver_loss, spleen_loss, any_in_loss, avg_loss = calculate_loss(X_out, X_any, y)\n",
    "            \n",
    "        step = 'train'\n",
    "        wandb.log({ 'lr': current_lr,\n",
    "                    f'{step}_bowel_loss': bowel_loss.item(),\n",
    "                    f'{step}_extrav_loss': extrav_loss.item(),\n",
    "                    f'{step}_kidney_loss': kidney_loss.item(),\n",
    "                    f'{step}_liver_loss': liver_loss.item(),\n",
    "                    f'{step}_spleen_loss': spleen_loss.item(),\n",
    "                    f'{step}_any_loss': any_in_loss.item(),\n",
    "                    f'{step}_avg_loss': avg_loss.item()\n",
    "                    })\n",
    "        \n",
    "        scaler.scale(avg_loss/accum_scale[accum_counter]).backward()\n",
    "        if(counter==accum_points[accum_counter]):\n",
    "            scaler.step(optimizer)\n",
    "            scheduler.step()\n",
    "            scaler.update()    \n",
    "            accum_counter+=1                \n",
    "    counter+=1                   \n",
    "\n",
    "    #Metric calculation\n",
    "    y_any = torch.cat([torch.ones(batch_size, 1).to(DEVICE)- y[:,13:14],y[:,13:14]], dim = 1)    \n",
    "    X_out = apply_softmax_to_labels(X_out).detach().to('cpu').numpy()\n",
    "    X_any = X_any.detach().to('cpu').numpy()\n",
    "    X_out = np.hstack([X_out, X_any])\n",
    "    X_outs.append(X_out)\n",
    "\n",
    "    y     = y.to('cpu').numpy()[:,:-1]\n",
    "    y_any = y_any.to('cpu').numpy()\n",
    "    y     = np.hstack([y, y_any])\n",
    "    ys.append(y)\n",
    "\n",
    "    trn_loss = avg_loss.item()      \n",
    "    train_meters['loss'].update(trn_loss, n=batch_size)     \n",
    "    #pbar.set_description(f'Train loss: {trn_loss}')   \n",
    "    \n",
    "    \n",
    "print('Epoch {:d} / trn/loss={:.4f}'.format(epoch+1, train_meters['loss'].avg))    \n",
    "\n",
    "X_outs = np.vstack(X_outs) \n",
    "ys     = np.vstack(ys)\n",
    "metric = calculate_score(X_outs, ys, 'train')                 \n",
    "print('Epoch {:d} / train/metric={:.4f}'.format(epoch+1, metric))   \n",
    "\n",
    "del X_bowel, X_lkid, X_rkid, X_liv, X_spl, X_tot, X_outs, y, ys, X_any\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
