{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57d0c4d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-11T02:52:20.973158Z",
     "iopub.status.busy": "2024-01-11T02:52:20.972631Z",
     "iopub.status.idle": "2024-01-11T02:52:33.574371Z",
     "shell.execute_reply": "2024-01-11T02:52:33.572596Z"
    },
    "papermill": {
     "duration": 12.618203,
     "end_time": "2024-01-11T02:52:33.577525",
     "exception": false,
     "start_time": "2024-01-11T02:52:20.959322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseonglee/miniconda3/envs/llm_detect/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tokenizers import (\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    "    SentencePieceBPETokenizer,\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "IS_KAGGLE = True\n",
    "if os.path.isdir(\"/kaggle/input\"):\n",
    "    sys.path.append(\n",
    "        \"/kaggle/input/llm-detect-github/LLM-Detect-AI-Generated-Text-main/main\"\n",
    "    )\n",
    "else:\n",
    "    sys.path.append(f\"{os.getcwd()[:-9]}/main\")\n",
    "    IS_KAGGLE = False\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier, sum_models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy import sparse\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from utils import (\n",
    "    save_pickle,\n",
    "    weighted_average_preds,\n",
    "    OptunaEarlyStoppingCallback,\n",
    "    last_fold_changer,\n",
    "    models_excluder,\n",
    "    append_preds,\n",
    ")\n",
    "from modules import model_objectives\n",
    "from params import select_param_type\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc012ef",
   "metadata": {
    "papermill": {
     "duration": 0.008269,
     "end_time": "2024-01-11T02:52:33.594351",
     "exception": false,
     "start_time": "2024-01-11T02:52:33.586082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36673027",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:52:33.612389Z",
     "iopub.status.busy": "2024-01-11T02:52:33.611887Z",
     "iopub.status.idle": "2024-01-11T02:52:33.631028Z",
     "shell.execute_reply": "2024-01-11T02:52:33.629807Z"
    },
    "papermill": {
     "duration": 0.031825,
     "end_time": "2024-01-11T02:52:33.634198",
     "exception": false,
     "start_time": "2024-01-11T02:52:33.602373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "USE_PREV_ERROR = False\n",
    "\n",
    "# preprocessing part\n",
    "EXTRA_INDS = []  # np.arange(0, 11)\n",
    "N_FOLDS = 11\n",
    "MODEL_FOR_ENSEMBLE = \"gpt\"\n",
    "MODELS_TO_EXCLUDE = [\"davinci\", \"curie\", \"llama\", \"babbage\", \"ada\", \"palm\"]\n",
    "ROOT = \"/kaggle/input\" if IS_KAGGLE else \"../input\"\n",
    "SAVE_ROOT = \"/tmp\" if IS_KAGGLE else \"../input\"\n",
    "SEED = 99\n",
    "LOWERCASE = False\n",
    "VOCAB_SIZE = 30522\n",
    "VECTORIZER_VOCAB_SAMPLE_RATIO = 0.01  # for test use all\n",
    "PROCESSED_PATH = f\"{SAVE_ROOT}/230110_0.05_v2_10folds\"\n",
    "NORMALIZER = normalizers.NFC()  # {\"nfc\": NFC, \"nfd\": NFD, \"nfkc\": NFKC, \"nfkd\": NFKD}\n",
    "os.makedirs(f\"{PROCESSED_PATH}\", exist_ok=True)  # splitted x vectorized\n",
    "\n",
    "# model part\n",
    "INPUT_TYPE = \"sentence\"  # sentence, bpe\n",
    "MODEL = \"LGBM\"  # LGBM, XGB, CatBoost\n",
    "LOWERCASE = False\n",
    "N_ESTIMATORS = 2000\n",
    "N_OPTUNA_TRIALS = 10\n",
    "OPTUNA_EARLY_STOP_COUNT = 5\n",
    "N_OPTUNA_ENSEMBLE_TRIALS = 10000\n",
    "OPTUNA_ENSEMBLE_EARLY_STOP_COUNT = 1000\n",
    "LGBM_SENTENCE_PARAMS =   {'verbosity': -1, 'random_state': 42, 'early_stopping_rounds': 100, 'metric': 'auc', 'learning_rate': 0.07286724587922155, 'colsample_bytree': 0.6797905694389136, 'colsample_bynode': 0.839733458908106, 'lambda_l1': 0.38796147682692317, 'lambda_l2': 0.29300104388528725, 'max_depth': 14, 'num_leaves': 81, 'min_data_in_leaf': 150, 'min_child_weight': 0.001616998311835574, 'min_child_samples': 2, 'max_bin': 1022, 'subsample': 0.9885898125913607, 'subsample_freq': 0}\n",
    "SGD_SENTENCE_PARAMS = {'max_iter': 5132, 'loss': 'modified_huber', 'penalty': 'l2', 'alpha': 0.00029234336294386683, 'learning_rate': 'invscaling', 'eta0': 0.8611233723469085, 'early_stopping': True, 'n_iter_no_change': 100, 'warm_start': True, 'n_jobs': -1}\n",
    "MULTINOMIALNB_SENTENCE_PARAMS = {\"alpha\": 0.02}\n",
    "COMPLEMENTNB_SENTENCE_PARAMS = {'alpha': 0.004243397640210257, 'force_alpha': False, 'fit_prior': True, 'norm': False}\n",
    "RIDGE_SENTENCE_PARAMS = {'max_iter': 8070, 'fit_intercept': True, 'alpha': 0.0028878876055973765}\n",
    "PASSIVE_SENTENCE_PARAMS = {'C': 0.891141518158109, 'max_iter': 5052, 'fit_intercept': False, 'early_stopping': True, 'loss': 'hinge', 'warm_start': False, 'average': 6}\n",
    "\n",
    "N_SPLIT_CATBOOST_TRAIN = 8\n",
    "N_SPLIT_CATBOOST_GROUP = 2\n",
    "\n",
    "if DEBUG:\n",
    "    #N_ESTIMATORS = 10\n",
    "    if IS_KAGGLE:\n",
    "        !cp -r /kaggle/input/sentencepiece-refined-preprocessed/230109_on-the-fly_0.05_v2 /tmp\n",
    "    N_OPTUNA_TRIALS = 2\n",
    "    OPTUNA_EARLY_STOP_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f954da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:52:33.655598Z",
     "iopub.status.busy": "2024-01-11T02:52:33.655175Z",
     "iopub.status.idle": "2024-01-11T02:52:33.680716Z",
     "shell.execute_reply": "2024-01-11T02:52:33.678783Z"
    },
    "papermill": {
     "duration": 0.041199,
     "end_time": "2024-01-11T02:52:33.684655",
     "exception": true,
     "start_time": "2024-01-11T02:52:33.643456",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fast save\n",
    "IS_RERUN = False\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    IS_RERUN = True\n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        sub = pd.read_csv(\n",
    "            \"/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\"\n",
    "        )\n",
    "        sub.to_csv(\"submission.csv\", index=False)\n",
    "    except:\n",
    "        sub = pd.read_csv(\"../input/llm-detect-ai-generated-text/sample_submission.csv\")\n",
    "        sub.to_csv(\"submission.csv\", index=False)\n",
    "if (not DEBUG) and (not IS_RERUN) and (IS_KAGGLE):\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10b8543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:51:13.335106Z",
     "iopub.status.busy": "2024-01-11T02:51:13.334664Z",
     "iopub.status.idle": "2024-01-11T02:51:15.021965Z",
     "shell.execute_reply": "2024-01-11T02:51:15.021044Z",
     "shell.execute_reply.started": "2024-01-11T02:51:13.335065Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt' 'human']\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(f\"{ROOT}/llm-detect-ai-generated-text/test_essays.csv\")\n",
    "sub = pd.read_csv(f\"{ROOT}/llm-detect-ai-generated-text/sample_submission.csv\")\n",
    "org_train = pd.read_csv(f\"{ROOT}/llm-detect-ai-generated-text/train_essays.csv\")\n",
    "org_train = org_train.sample(frac=1.0, random_state=SEED)\n",
    "org_train.reset_index(drop=True, inplace=True)\n",
    "train_path = (\n",
    "    f\"{ROOT}/llm-daigt-5fold-split-seed7-train/20230112_model-wise-split_all-data.csv\"\n",
    "    if IS_KAGGLE\n",
    "    else f\"{ROOT}/20230112_model-wise-split_all-data.csv\"\n",
    ")\n",
    "train = pd.read_csv(train_path)\n",
    "train = train.drop_duplicates(subset=[\"text\"])\n",
    "train = last_fold_changer(train, MODEL_FOR_ENSEMBLE)\n",
    "train = models_excluder(train, MODELS_TO_EXCLUDE)\n",
    "\n",
    "print(np.unique(train.loc[train.fold == N_FOLDS - 1].model))\n",
    "train = train.sample(frac=1.0, random_state=SEED)\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020eb806",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Sample each source for vocab calculation for the tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a6db02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:51:16.190837Z",
     "iopub.status.busy": "2024-01-11T02:51:16.190315Z",
     "iopub.status.idle": "2024-01-11T02:51:16.275118Z",
     "shell.execute_reply": "2024-01-11T02:51:16.274234Z",
     "shell.execute_reply.started": "2024-01-11T02:51:16.190810Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1880"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_source = np.unique(train[\"model\"])\n",
    "texts_sampled_for_vectorizer_vocab = pd.DataFrame()\n",
    "texts_remains = pd.DataFrame()\n",
    "for source in list_source:\n",
    "    train_one_source = train.loc[train.model == source]\n",
    "    n_samples = int(len(train_one_source) * VECTORIZER_VOCAB_SAMPLE_RATIO)\n",
    "    remain_one_source = train_one_source.iloc[n_samples:]\n",
    "    train_one_source = train_one_source.iloc[:n_samples]\n",
    "    texts_remains = pd.concat([texts_remains, remain_one_source])\n",
    "    texts_sampled_for_vectorizer_vocab = pd.concat(\n",
    "        [texts_sampled_for_vectorizer_vocab, train_one_source]\n",
    "    )\n",
    "# Also add org_train\n",
    "texts_sampled_for_vectorizer_vocab = pd.concat(\n",
    "    [\n",
    "        texts_sampled_for_vectorizer_vocab,\n",
    "        org_train.iloc[: int(len(org_train))],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# For submission\n",
    "if len(test) > 3:\n",
    "    texts_sampled_for_vectorizer_vocab = pd.concat(\n",
    "        [\n",
    "            texts_sampled_for_vectorizer_vocab,\n",
    "            test.iloc[: int(len(test))],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "len(texts_sampled_for_vectorizer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb49fc59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:51:16.361537Z",
     "iopub.status.busy": "2024-01-11T02:51:16.361143Z",
     "iopub.status.idle": "2024-01-11T02:51:16.367029Z",
     "shell.execute_reply": "2024-01-11T02:51:16.365438Z",
     "shell.execute_reply.started": "2024-01-11T02:51:16.361505Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# partial_train_for_ensemble = train.loc[train[\"fold\"] == N_FOLDS - 1]\n",
    "# train = train.loc[train[\"fold\"] != N_FOLDS - 1]\n",
    "# N_FOLDS = N_FOLDS - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33c790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T13:01:56.408328Z",
     "iopub.status.busy": "2024-01-06T13:01:56.407845Z",
     "iopub.status.idle": "2024-01-06T13:01:56.423346Z",
     "shell.execute_reply": "2024-01-06T13:01:56.421036Z",
     "shell.execute_reply.started": "2024-01-06T13:01:56.408301Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Tokenize splitted folds and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec933aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:51:17.151841Z",
     "iopub.status.busy": "2024-01-11T02:51:17.150640Z",
     "iopub.status.idle": "2024-01-11T02:51:17.164605Z",
     "shell.execute_reply": "2024-01-11T02:51:17.163422Z",
     "shell.execute_reply.started": "2024-01-11T02:51:17.151786Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_texts(raw_tokenizer, texts):\n",
    "    tokenizer = PreTrainedTokenizerFast(\n",
    "        tokenizer_object=raw_tokenizer,\n",
    "        unk_token=\"[UNK]\",\n",
    "        pad_token=\"[PAD]\",\n",
    "        cls_token=\"[CLS]\",\n",
    "        sep_token=\"[SEP]\",\n",
    "        mask_token=\"[MASK]\",\n",
    "    )\n",
    "    tokenized_texts = []\n",
    "    for text in tqdm(texts[\"text\"].tolist()):\n",
    "        tokenized_texts.append(tokenizer.tokenize(text))\n",
    "    del raw_tokenizer, tokenizer\n",
    "    gc.collect()\n",
    "    return tokenized_texts\n",
    "\n",
    "\n",
    "def sentence_piece_bpe_tokenizer(train, org_train, sampled, remains, test):\n",
    "    raw_tokenizer = SentencePieceBPETokenizer()\n",
    "    raw_tokenizer.normalizer = normalizers.Sequence(\n",
    "        [NORMALIZER] + [normalizers.Lowercase()] if LOWERCASE else []\n",
    "    )\n",
    "    raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "    merged_pd = pd.concat([train, org_train])\n",
    "    dataset = Dataset.from_pandas(merged_pd[[\"text\"]])\n",
    "\n",
    "    def train_corp_iter():\n",
    "        for i in range(0, len(dataset), 300):\n",
    "            yield dataset[i : i + 300][\"text\"]\n",
    "\n",
    "    raw_tokenizer.train_from_iterator(train_corp_iter())\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "\n",
    "    tokenized_texts_train = tokenize_texts(raw_tokenizer, train)\n",
    "    tokenized_texts_org_train = tokenize_texts(raw_tokenizer, org_train)\n",
    "    tokenized_texts_sampled = tokenize_texts(raw_tokenizer, sampled)\n",
    "    tokenized_texts_remains = tokenize_texts(raw_tokenizer, remains)\n",
    "    tokenized_texts_test = tokenize_texts(raw_tokenizer, test)\n",
    "    return (\n",
    "        tokenized_texts_train,\n",
    "        tokenized_texts_org_train,\n",
    "        tokenized_texts_sampled,\n",
    "        tokenized_texts_remains,\n",
    "        tokenized_texts_test,\n",
    "    )\n",
    "\n",
    "\n",
    "def bpe_tokenizer(train, org_train, sampled, remains, test):\n",
    "    raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "    raw_tokenizer.normalizer = normalizers.Sequence(\n",
    "        [NORMALIZER] + [normalizers.Lowercase()] if LOWERCASE else []\n",
    "    )\n",
    "    raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "    special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "    trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n",
    "    merged_pd = pd.concat([train, org_train])\n",
    "    dataset = Dataset.from_pandas(merged_pd[[\"text\"]])\n",
    "\n",
    "    def train_corp_iter():\n",
    "        for i in range(0, len(dataset), 1000):\n",
    "            yield dataset[i : i + 1000][\"text\"]\n",
    "\n",
    "    raw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\n",
    "    del dataset\n",
    "    gc.collect()\n",
    "\n",
    "    tokenized_texts_train = tokenize_texts(raw_tokenizer, train)\n",
    "    tokenized_texts_org_train = tokenize_texts(raw_tokenizer, org_train)\n",
    "    tokenized_texts_sampled = tokenize_texts(raw_tokenizer, sampled)\n",
    "    tokenized_texts_remains = tokenize_texts(raw_tokenizer, remains)\n",
    "    tokenized_texts_test = tokenize_texts(raw_tokenizer, test)\n",
    "    return (\n",
    "        tokenized_texts_train,\n",
    "        tokenized_texts_org_train,\n",
    "        tokenized_texts_sampled,\n",
    "        tokenized_texts_remains,\n",
    "        tokenized_texts_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe52542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:51:17.293047Z",
     "iopub.status.busy": "2024-01-11T02:51:17.292647Z",
     "iopub.status.idle": "2024-01-11T02:51:17.301042Z",
     "shell.execute_reply": "2024-01-11T02:51:17.299570Z",
     "shell.execute_reply.started": "2024-01-11T02:51:17.293003Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dummy(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "def vectorizer_fit_sampled_vectorize_all(\n",
    "    train_tokens, org_train_tokens, sampled_tokens, remain_tokens, test_tokens\n",
    "):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        lowercase=False,\n",
    "        sublinear_tf=True,\n",
    "        analyzer=\"word\",\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        token_pattern=None,\n",
    "        strip_accents=\"unicode\",\n",
    "        binary=True,\n",
    "    )\n",
    "    vectorizer.fit(sampled_tokens)\n",
    "    vocab = vectorizer.vocabulary_\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        lowercase=False,\n",
    "        sublinear_tf=True,\n",
    "        vocabulary=vocab,\n",
    "        analyzer=\"word\",\n",
    "        tokenizer=dummy,\n",
    "        preprocessor=dummy,\n",
    "        token_pattern=None,\n",
    "        strip_accents=\"unicode\",\n",
    "        binary=True,\n",
    "    )\n",
    "    vectorizer.fit(remain_tokens)\n",
    "    tf_train = vectorizer.transform(train_tokens)\n",
    "    tf_org_train = vectorizer.transform(org_train_tokens)\n",
    "    tf_test = vectorizer.transform(test_tokens)\n",
    "    del vectorizer\n",
    "    gc.collect()\n",
    "    return (tf_train, tf_org_train, tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2c578f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-11T02:51:17.415973Z",
     "iopub.status.busy": "2024-01-11T02:51:17.415550Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50481/50481 [00:24<00:00, 2034.45it/s]\n",
      "100%|██████████| 1378/1378 [00:00<00:00, 1571.46it/s]\n",
      "100%|██████████| 1880/1880 [00:01<00:00, 1685.89it/s]\n",
      "100%|██████████| 49979/49979 [00:25<00:00, 1970.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 18641.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50481, 245614)\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_with_vectorizer(train, org_train, sampled, remains, test, option):\n",
    "    train_y = train[\"generated\"].values\n",
    "    org_train_y = org_train[\"generated\"].values\n",
    "\n",
    "    if option == \"sentence\":\n",
    "        (\n",
    "            tokenized_texts_train,\n",
    "            tokenized_texts_org_train,\n",
    "            tokenized_texts_sampled,\n",
    "            tokenized_texts_remains,\n",
    "            tokenized_texts_test,\n",
    "        ) = sentence_piece_bpe_tokenizer(train, org_train, sampled, remains, test)\n",
    "    elif option == \"bpe\":\n",
    "        (\n",
    "            tokenized_texts_train,\n",
    "            tokenized_texts_org_train,\n",
    "            tokenized_texts_sampled,\n",
    "            tokenized_texts_remains,\n",
    "            tokenized_texts_test,\n",
    "        ) = bpe_tokenizer(train, org_train, sampled, remains, test)\n",
    "\n",
    "    tf_train, tf_org_train, tf_test = vectorizer_fit_sampled_vectorize_all(\n",
    "        tokenized_texts_train,\n",
    "        tokenized_texts_org_train,\n",
    "        tokenized_texts_sampled,\n",
    "        tokenized_texts_remains,\n",
    "        tokenized_texts_test,\n",
    "    )\n",
    "\n",
    "    save_base = f\"{PROCESSED_PATH}/{option}_seed{SEED}_\"\n",
    "    print(tf_train.shape)\n",
    "    save_pickle(f\"{save_base}train.pkl\", [tf_train, train_y, train[\"fold\"].values])\n",
    "    save_pickle(f\"{save_base}org_train.pkl\", [tf_org_train, org_train_y])\n",
    "    save_pickle(f\"{save_base}test.pkl\", tf_test)\n",
    "\n",
    "    del (\n",
    "        tokenized_texts_train,\n",
    "        tokenized_texts_org_train,\n",
    "        tokenized_texts_sampled,\n",
    "        tokenized_texts_remains,\n",
    "        tokenized_texts_test,\n",
    "        tf_train,\n",
    "        tf_org_train,\n",
    "    )\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "if not DEBUG:\n",
    "    sampled = texts_sampled_for_vectorizer_vocab\n",
    "    remains = texts_remains\n",
    "    tokenizer_with_vectorizer(train, org_train, sampled, remains, test, \"sentence\")\n",
    "    # tokenizer_with_vectorizer(train, org_train, sampled, remains, test, \"bpe\")\n",
    "    del train, org_train, sampled, remains, test, texts_sampled_for_vectorizer_vocab\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004da89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Fit & inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ef1e7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Optuna fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc3af7e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optuna_optimization(\n",
    "    opt_mode,\n",
    "    model,\n",
    "    n_folds,\n",
    "    data_path,\n",
    "    input_type,\n",
    "    first_trial_param,\n",
    "    seed,\n",
    "    early_count,\n",
    "):\n",
    "    early = OptunaEarlyStoppingCallback(early_stop_count=early_count)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\", study_name=\"Classifier\", sampler=sampler\n",
    "    )\n",
    "    if first_trial_param is not None:\n",
    "        study.enqueue_trial(first_trial_param)\n",
    "\n",
    "    def select_model_objectives(\n",
    "        trial,\n",
    "        opt_mode=opt_mode,\n",
    "        model=model,\n",
    "        n_folds=n_folds,\n",
    "        data_path=data_path,\n",
    "        input_type=input_type,\n",
    "        seed=seed,\n",
    "    ):\n",
    "        params = select_param_type(model)\n",
    "\n",
    "        return model_objectives(\n",
    "            trial,\n",
    "            N_ESTIMATORS,\n",
    "            opt_mode,\n",
    "            model,\n",
    "            n_folds,\n",
    "            data_path,\n",
    "            input_type,\n",
    "            seed,\n",
    "            params,\n",
    "            USE_PREV_ERROR,\n",
    "            DEBUG,\n",
    "        )\n",
    "\n",
    "    study.optimize(\n",
    "        select_model_objectives,\n",
    "        n_trials=N_OPTUNA_TRIALS,\n",
    "        show_progress_bar=True,\n",
    "        callbacks=[early],\n",
    "    )\n",
    "    print(f\"Best auc: {study.best_value}\")\n",
    "    return study\n",
    "\n",
    "\n",
    "def optuna_ensemble_optimization(seed, early_count, pred_for_ensembles, y_for_ensemble):\n",
    "    early = OptunaEarlyStoppingCallback(early_stop_count=early_count)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\", study_name=\"Classifier\", sampler=sampler\n",
    "    )\n",
    "\n",
    "    def ensemble_params_sweep_range(trial, n_preds=len(pred_for_ensembles)):\n",
    "        params = {}\n",
    "        for i in range(0, n_preds):\n",
    "            params[f\"weight_{i}\"] = (trial.suggest_float(f\"weight_{i}\", -1.0, 1.0),)\n",
    "        return params\n",
    "\n",
    "    def ensemble_objective(\n",
    "        trial,\n",
    "        param_range=ensemble_params_sweep_range,\n",
    "        pred_for_ensembles=pred_for_ensembles,\n",
    "        y_for_ensemble=y_for_ensemble,\n",
    "    ):\n",
    "        params = param_range(trial)\n",
    "        weights = []\n",
    "        for i in range(0, len(pred_for_ensembles)):\n",
    "            weights.append(params[f\"weight_{i}\"])\n",
    "        pred = np.clip(weighted_average_preds(pred_for_ensembles, weights), 0, 1)\n",
    "        return roc_auc_score(y_for_ensemble, pred)\n",
    "\n",
    "    study.optimize(\n",
    "        ensemble_objective,\n",
    "        n_trials=N_OPTUNA_ENSEMBLE_TRIALS,\n",
    "        show_progress_bar=False,\n",
    "        callbacks=[early],\n",
    "    )\n",
    "    print(f\"Best auc: {study.best_value}\")\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fc0f9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "SGD_SENTENCE_PARAMS[\"max_iter\"] = 100 if DEBUG else SGD_SENTENCE_PARAMS[\"max_iter\"]\n",
    "\n",
    "optuna_opt_args = {\n",
    "    \"opt_mode\": \"coarse\",\n",
    "    \"model\": \"LGBM\",\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"data_path\": PROCESSED_PATH,\n",
    "    \"input_type\": \"sentence\",\n",
    "    \"first_trial_param\": None,\n",
    "    \"seed\": SEED,\n",
    "    \"early_count\": OPTUNA_EARLY_STOP_COUNT,\n",
    "}\n",
    "\n",
    "optuna_opt_args[\"first_trial_param\"] = LGBM_SENTENCE_PARAMS\n",
    "lgbm_study = optuna_optimization(**optuna_opt_args)\n",
    "LGBM_SENTENCE_PARAMS = lgbm_study.best_params\n",
    "del lgbm_study\n",
    "gc.collect()\n",
    "\n",
    "optuna_opt_args[\"first_trial_param\"] = SGD_SENTENCE_PARAMS\n",
    "optuna_opt_args[\"model\"] = \"SGD\"\n",
    "sgd_study = optuna_optimization(**optuna_opt_args)\n",
    "SGD_SENTENCE_PARAMS = sgd_study.best_params\n",
    "del sgd_study\n",
    "gc.collect()\n",
    "\n",
    "optuna_opt_args[\"first_trial_param\"] = MULTINOMIALNB_SENTENCE_PARAMS\n",
    "optuna_opt_args[\"model\"] = \"multinomialNB\"\n",
    "multinomialnb_study = optuna_optimization(**optuna_opt_args)\n",
    "MULTINOMIALNB_SENTENCE_PARAMS = multinomialnb_study.best_params\n",
    "del multinomialnb_study\n",
    "gc.collect()\n",
    "\n",
    "optuna_opt_args[\"first_trial_param\"] = COMPLEMENTNB_SENTENCE_PARAMS\n",
    "optuna_opt_args[\"model\"] = \"complementNB\"\n",
    "sgd_study = optuna_optimization(**optuna_opt_args)\n",
    "COMPLEMENTNB_SENTENCE_PARAMS = sgd_study.best_params\n",
    "del sgd_study\n",
    "gc.collect()\n",
    "\n",
    "optuna_opt_args[\"first_trial_param\"] = RIDGE_SENTENCE_PARAMS\n",
    "optuna_opt_args[\"model\"] = \"ridge\"\n",
    "multinomialnb_study = optuna_optimization(**optuna_opt_args)\n",
    "RIDGE_SENTENCE_PARAMS = multinomialnb_study.best_params\n",
    "del multinomialnb_study\n",
    "gc.collect()\n",
    "\n",
    "optuna_opt_args[\"first_trial_param\"] = PASSIVE_SENTENCE_PARAMS\n",
    "optuna_opt_args[\"model\"] = \"passiveAggresive\"\n",
    "multinomialnb_study = optuna_optimization(**optuna_opt_args)\n",
    "PASSIVE_SENTENCE_PARAMS = multinomialnb_study.best_params\n",
    "del multinomialnb_study\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582649d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9066a18f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Don't forget to clip ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417a16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_and_append_it(\n",
    "    model_obj_args, model_name, model_params, pred_tests, pred_for_ensembles\n",
    "):\n",
    "    model_obj_args[\"model_name\"] = model_name\n",
    "    model_obj_args[\"model_params\"] = model_params\n",
    "    pred_test, pred_for_ensemble, y_for_ensemble = model_objectives(**model_obj_args)\n",
    "    pred_tests = append_preds(pred_tests, pred_test)\n",
    "    pred_for_ensembles = append_preds(pred_for_ensembles, pred_for_ensemble)\n",
    "    return pred_tests, pred_for_ensembles, y_for_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde34d07",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junseonglee/miniconda3/envs/llm_detect/lib/python3.11/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.38796147682692317, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.38796147682692317\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=2 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29300104388528725, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29300104388528725\n"
     ]
    }
   ],
   "source": [
    "fit_method = \"infer_one_fold\" if DEBUG else \"infer_all_folds\"\n",
    "# SGD_SENTENCE_PARAMS[\"max_iter\"] = 100 if DEBUG else SGD_SENTENCE_PARAMS[\"max_iter\"]\n",
    "fit_method = \"infer_one_fold\"\n",
    "\n",
    "model_obj_args = {\n",
    "    \"trial\": None,\n",
    "    \"n_estimators\": N_ESTIMATORS,\n",
    "    \"opt_mode\": fit_method,\n",
    "    \"model_name\": \"LGBM\",\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"data_path\": PROCESSED_PATH,\n",
    "    \"input_type\": \"sentence\",\n",
    "    \"seed\": SEED,\n",
    "    \"model_params\": LGBM_SENTENCE_PARAMS,\n",
    "    \"use_prev_error\": USE_PREV_ERROR,\n",
    "    \"debug\": DEBUG,\n",
    "}\n",
    "\n",
    "pred_tests = []\n",
    "pred_for_ensembles = []\n",
    "\n",
    "\n",
    "pred_tests, pred_for_ensembles, y_for_ensemble = pred_and_append_it(\n",
    "    model_obj_args, \"LGBM\", LGBM_SENTENCE_PARAMS, pred_tests, pred_for_ensembles\n",
    ")\n",
    "pred_tests, pred_for_ensembles, y_for_ensemble = pred_and_append_it(\n",
    "    model_obj_args, \"SGD\", SGD_SENTENCE_PARAMS, pred_tests, pred_for_ensembles\n",
    ")\n",
    "pred_tests, pred_for_ensembles, y_for_ensemble = pred_and_append_it(\n",
    "    model_obj_args,\n",
    "    \"multinomialNB\",\n",
    "    MULTINOMIALNB_SENTENCE_PARAMS,\n",
    "    pred_tests,\n",
    "    pred_for_ensembles,\n",
    ")\n",
    "pred_tests, pred_for_ensembles, y_for_ensemble = pred_and_append_it(\n",
    "    model_obj_args,\n",
    "    \"complementNB\",\n",
    "    COMPLEMENTNB_SENTENCE_PARAMS,\n",
    "    pred_tests,\n",
    "    pred_for_ensembles,\n",
    ")\n",
    "pred_tests, pred_for_ensembles, y_for_ensemble = pred_and_append_it(\n",
    "    model_obj_args, \"ridge\", RIDGE_SENTENCE_PARAMS, pred_tests, pred_for_ensembles\n",
    ")\n",
    "pred_tests, pred_for_ensembles, y_for_ensemble = pred_and_append_it(\n",
    "    model_obj_args,\n",
    "    \"passiveAggresive\",\n",
    "    PASSIVE_SENTENCE_PARAMS,\n",
    "    pred_tests,\n",
    "    pred_for_ensembles,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb05e99",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Ensemble param optimization\n",
    "Optuna optimization of the weights of the preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6035aff2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna study early stopped by early_stop_count\n",
      "Best auc: 0.9992349274473428\n",
      "{'weight_0': -0.11483735183271758, 'weight_1': -0.8917005018676765, 'weight_2': 0.32939724923805924, 'weight_3': -0.32093536935194145, 'weight_4': -0.09556739060888797, 'weight_5': -0.3984398774889969}\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.disable_default_handler()\n",
    "ensemble_study = optuna_ensemble_optimization(\n",
    "    SEED,\n",
    "    OPTUNA_ENSEMBLE_EARLY_STOP_COUNT,\n",
    "    pred_for_ensembles,\n",
    "    y_for_ensemble,\n",
    ")\n",
    "print(ensemble_study.best_params)\n",
    "model_weights = []\n",
    "for k in ensemble_study.best_params.keys():\n",
    "    model_weights.append(ensemble_study.best_params[k])\n",
    "\n",
    "sentence_pred = weighted_average_preds(pred_tests, model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cfb9c2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.257108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.256556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.269426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.257108\n",
       "1  1111bbbb   0.256556\n",
       "2  2222cccc   0.269426"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = sentence_pred\n",
    "sub[\"generated\"] = final_pred\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7069d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 7064285,
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7384423,
     "datasetId": 4210720,
     "sourceId": 7294503,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7471275,
     "datasetId": 4228964,
     "sourceId": 7380433,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7465418,
     "datasetId": 4268106,
     "sourceId": 7374672,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7460705,
     "datasetId": 4271058,
     "sourceId": 7370140,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.569919,
   "end_time": "2024-01-11T02:52:36.653981",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-11T02:52:16.084062",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
